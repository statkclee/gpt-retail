{
  "hash": "3b4280490d2f5b305ecbed06f5699fe3",
  "result": {
    "engine": "knitr",
    "markdown": "# OpenAI API\\index{OpenAI API}\n\nOpenAI API\\index{OpenAI API}ëŠ” ìµœì‹  ì¸ê³µì§€ëŠ¥ ëª¨ë¸ë“¤ì„ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¥¼ í†µí•´ í™œìš©í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ê°•ë ¥í•œ ë„êµ¬ë‹¤. GPT-4o\\index{GPT-4o}, DALLÂ·E\\index{DALLÂ·E} 3, Whisper\\index{Whisper} ë“±ì˜ ì²¨ë‹¨ ëª¨ë¸ì— ì ‘ê·¼í•˜ì—¬ í…ìŠ¤íŠ¸ ìƒì„±, ì´ë¯¸ì§€ ìƒì„±, ìŒì„± ì²˜ë¦¬, ì„ë² ë”© ìƒì„± ë“± ë‹¤ì–‘í•œ AI ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤. OpenAI APIì˜ ì „ì²´ êµ¬ì¡°ì™€ ì£¼ìš” ê¸°ëŠ¥ë“¤ì´ @fig-openai-diagram ì œì‹œë˜ì–´ ìˆë‹¤.\n\n```{mermaid}\n%%| label: fig-openai-diagram\n%%| fig-cap: \"OpenAI API ì „ì²´ êµ¬ì¡°ì™€ í™œìš© ë°©ì•ˆ\"\n%%| fig-width: 4\ngraph LR\n    subgraph Setup [\"ğŸ”§ ì„¤ì •\"]\n        User[ğŸ‘¤ ê°œë°œì]\n        Client[ğŸ“± OpenAI<br/>í´ë¼ì´ì–¸íŠ¸]\n        User --> Client\n    end\n    \n    subgraph Core [\"ğŸ¯ í•µì‹¬ API\"]\n        direction TB\n        \n        subgraph Text [\"ğŸ’¬ í…ìŠ¤íŠ¸\"]\n            Chat[Chat API]\n            Models1[\"GPT-4o/mini<br/>o1 ì‹œë¦¬ì¦ˆ\"]\n            Chat --- Models1\n        end\n        \n        subgraph Media [\"ğŸ¨ ë¯¸ë””ì–´\"]\n            Audio[ğŸµ ìŒì„±]\n            Image[ğŸ–¼ï¸ ì´ë¯¸ì§€]\n            Models2[\"Whisper-1<br/>DALLÂ·E 3/2\"]\n            Audio --- Models2\n            Image --- Models2\n        end\n        \n        subgraph Data [\"ğŸ“Š ë°ì´í„°\"]\n            Embed[ğŸ”¢ ì„ë² ë”©]\n            Mod[ğŸ›¡ï¸ ì¤‘ì¬]\n            Models3[\"embedding-3<br/>moderation\"]\n            Embed --- Models3\n            Mod --- Models3\n        end\n    end\n    \n    subgraph Apps [\"ğŸ¯ í™œìš©\"]\n        direction TB\n        \n        subgraph Business [\"ğŸ’¼ ë¹„ì¦ˆë‹ˆìŠ¤\"]\n            Service[ğŸ¤– ê³ ê°ì„œë¹„ìŠ¤]\n            Analysis[ğŸ“ˆ ë¶„ì„]\n        end\n        \n        subgraph Tech [\"âš™ï¸ ê°œë°œ\"]\n            Code[ğŸ’» ì½”ë”©]\n            Search[ğŸ” ê²€ìƒ‰]\n        end\n        \n        subgraph Safe [\"ğŸ”’ ì•ˆì „\"]\n            Content[ğŸ›¡ï¸ ê´€ë¦¬]\n            Policy[ğŸ“‹ ì •ì±…]\n        end\n    end\n    \n    subgraph Opt [\"ğŸ’¡ ìµœì í™”\"]\n        direction LR\n        Strategy[ğŸ“Š ì „ëµ]\n        Cost[ğŸ’° ë¹„ìš©]\n        Monitor[ğŸ“ˆ ëª¨ë‹ˆí„°ë§]\n        \n        Strategy --> Cost\n        Cost --> Monitor\n    end\n    \n    %% ì—°ê²°\n    Client --> Core\n    Text --> Business\n    Text --> Tech\n    Media --> Business\n    Data --> Safe\n    Core --> Apps\n    Client --> Opt\n    \n    %% ìŠ¤íƒ€ì¼\n    classDef setupStyle fill:#fce4ec,stroke:#c2185b,stroke-width:2px\n    classDef coreStyle fill:#e3f2fd,stroke:#1976d2,stroke-width:2px\n    classDef appStyle fill:#f1f8e9,stroke:#689f38,stroke-width:2px\n    classDef optStyle fill:#fff8e1,stroke:#f57c00,stroke-width:2px\n    \n    class Setup,User,Client setupStyle\n    class Core,Text,Media,Data,Chat,Audio,Image,Embed,Mod coreStyle\n    class Apps,Business,Tech,Safe appStyle\n    class Opt,Strategy,Cost,Monitor optStyle\n```\n\nAPI ì‚¬ìš© ì‹œ ë³´ì•ˆì´ ê°€ì¥ ì¤‘ìš”í•œ ê³ ë ¤ì‚¬í•­ì´ë‹¤. `.env` íŒŒì¼ì— OpenAI API-KEYë¥¼ ì €ì¥í•œ ê²½ìš° `.gitignore`ì— `.env`ë¥¼ ê¸°ë¡í•˜ì—¬ í˜‘ì—…ê³¼ ê³µê°œë¥¼ í•  ê²½ìš° ì£¼ìš” ì •ë³´ê°€ ì™¸ë¶€ì— ë…¸ì¶œë˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•œë‹¤.\n\n## `openai` íŒ¨í‚¤ì§€\n\nOpenAIì˜ íŒŒì´ì¬ í´ë¼ì´ì–¸íŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” API í˜¸ì¶œì„ ê°„í¸í•˜ê²Œ ë§Œë“¤ì–´ì£¼ëŠ” í•„ìˆ˜ ë„êµ¬ë‹¤. ì´ íŒ¨í‚¤ì§€ëŠ” ë³µì¡í•œ HTTP ìš”ì²­ì„ ê°„ë‹¨í•œ ë©”ì„œë“œ í˜¸ì¶œë¡œ ë³€í™˜í•´ì£¼ë©°, íƒ€ì… íŒíŠ¸ì™€ ìë™ì™„ì„±ì„ ì§€ì›í•˜ì—¬ ê°œë°œ ìƒì‚°ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚¨ë‹¤. GitHub ì €ì¥ì†Œ [OpenAI Python Library](https://github.com/openai/openai-python) [@openai2025python]ì˜ `openai` íŒŒì´ì¬ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•œ í›„ ë²„ì „ì„ í™•ì¸í•œë‹¤.\n\n\n::: {.cell}\n\n```{.python .cell-code .code-overflow-wrap}\n! pip install openai\n\n# ë²„ì „ í™•ì¸\n! pip show openai\n```\n:::\n\n\n## ê¸°ë³¸ ì„¤ì •\n\nAPI ì‚¬ìš© ì „ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì ì ˆíˆ ì´ˆê¸°í™”í•˜ëŠ” ê²ƒì´ ëª¨ë“  ì‘ì—…ì˜ ì¶œë°œì ì´ë‹¤. í™˜ê²½ë³€ìˆ˜ë¥¼ í†µí•œ API í‚¤ ê´€ë¦¬ëŠ” ë³´ì•ˆê³¼ í¸ì˜ì„±ì„ ë™ì‹œì— í™•ë³´í•˜ëŠ” ì—…ê³„ í‘œì¤€ ë°©ë²•ì´ë‹¤. OpenAI APIë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ê¸°ë³¸ ì„¤ì •ì€ ë‹¤ìŒê³¼ ê°™ë‹¤:\n\n\n::: {.cell}\n\n```{.python .cell-code .code-overflow-wrap}\nfrom openai import OpenAI\nfrom dotenv import load_dotenv\nimport os\n\n# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ\nload_dotenv()\n\n# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\nclient = OpenAI(\n    api_key=os.getenv('OPENAI_API_KEY')\n)\n```\n:::\n\n\n## í…ìŠ¤íŠ¸ API\n\ní…ìŠ¤íŠ¸(Chat Completions) APIëŠ” OpenAIì˜ í•µì‹¬ ê¸°ëŠ¥ìœ¼ë¡œ, ëŒ€í™”í˜• AIë¥¼ êµ¬í˜„í•˜ëŠ” ê°€ì¥ ì¼ë°˜ì ì¸ ë°©ë²•ì´ë‹¤. ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ í†µí•´ AIì˜ ì—­í• ê³¼ ì„±ê²©ì„ ì •ì˜í•˜ê³ , ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ í†µí•´ ì‹¤ì œ ì§ˆë¬¸ì´ë‚˜ ìš”ì²­ì„ ì „ë‹¬í•  ìˆ˜ ìˆë‹¤. ì˜¨ë„(temperature) ì„¤ì •ìœ¼ë¡œ ì‘ë‹µì˜ ì°½ì˜ì„±ì„ ì¡°ì ˆí•˜ë©°, ìµœëŒ€ í† í° ìˆ˜ë¡œ ì‘ë‹µ ê¸¸ì´ë¥¼ ì œí•œí•  ìˆ˜ ìˆë‹¤. ìµœì‹  OpenAI APIëŠ” `client.chat.completions.create()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•œë‹¤.\n\n\n::: {.cell}\n\n```{.python .cell-code .code-overflow-wrap}\nresponse = client.chat.completions.create(\n    model=\"gpt-4o-mini\",\n    messages=[\n        {\"role\": \"system\", \"content\": \"ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ë¡œ ëŒ€ë‹µë„ ê°„ê²°í•˜ê²Œ í•´\"},\n        {\"role\": \"user\", \"content\": \"íŒŒì´ì¬ê³¼ R ì¤‘ ì–´ë–¤ ì–¸ì–´ê°€ ë°ì´í„° ë¶„ì„ì— ë” ì í•©í•œê°€ìš”?\"}\n    ],\n    max_tokens=100,\n    temperature=0\n)\n\nprint(response.choices[0].message.content)\n```\n:::\n\n\n``` markdown\níŒŒì´ì¬ê³¼ R ëª¨ë‘ ë°ì´í„° ë¶„ì„ì— ì í•©í•˜ì§€ë§Œ, ê°ê°ì˜ ì¥ë‹¨ì ì´ ìˆìŠµë‹ˆë‹¤.\n\n- **íŒŒì´ì¬**: \n  - ë²”ìš© í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¡œ, ë°ì´í„° ë¶„ì„ ì™¸ì—ë„ ì›¹ ê°œë°œ, ìë™í™” ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ì‚¬ìš©.\n  - Pandas, NumPy, Matplotlib, Seaborn ë“± ê°•ë ¥í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì§€ì›.\n  - ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì— ê°•ì  (Scikit-learn,\n```\n\n::: callout-note\n### ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸\n\nì‘ì—…ì˜ ë³µì¡ì„±ê³¼ ì˜ˆì‚°ì— ë”°ë¼ ì ì ˆí•œ ëª¨ë¸ì„ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤. ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ì²˜ë¦¬ì—ëŠ” gpt-4o-miniê°€ íš¨ìœ¨ì ì´ë©°, ë³µì¡í•œ ì¶”ë¡ ì´ë‚˜ ë©€í‹°ëª¨ë‹¬ ì‘ì—…ì—ëŠ” gpt-4oë‚˜ o1 ì‹œë¦¬ì¦ˆê°€ ì í•©í•˜ë‹¤.\n\n-   `gpt-4o`: ê°€ì¥ ê°•ë ¥í•œ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ (ì´ë¯¸ì§€, í…ìŠ¤íŠ¸ ì²˜ë¦¬)\n-   `gpt-4o-mini`: GPT-4oì˜ ê²½ëŸ‰í™” ë²„ì „, ë¹ ë¥´ê³  ì €ë ´\n-   `gpt-4-turbo`: ìµœì‹  GPT-4 Turbo ëª¨ë¸ (128K ì»¨í…ìŠ¤íŠ¸)\n-   `gpt-4`: í‘œì¤€ GPT-4 ëª¨ë¸\n-   `gpt-3.5-turbo\\index{gpt-3.5-turbo}`: ë¹ ë¥´ê³  ì €ë ´í•œ ëª¨ë¸\n-   `o1-preview`: ë³µì¡í•œ ì¶”ë¡  ì‘ì—…ì— íŠ¹í™”ëœ ëª¨ë¸\n-   `o1-mini`: o1ì˜ ê²½ëŸ‰í™” ë²„ì „\n\n:::\n\n## ìŒì„± ì²˜ë¦¬\n\nWhisper APIë¥¼ í†µí•œ ìŒì„± ì²˜ë¦¬ëŠ” ë‹¤êµ­ì–´ ìŒì„± ì¸ì‹ê³¼ ë²ˆì—­ì„ ë™ì‹œì— ì§€ì›í•˜ëŠ” ê°•ë ¥í•œ ê¸°ëŠ¥ì´ë‹¤. ê¸°ì¡´ì˜ ìŒì„± ì¸ì‹ ì†”ë£¨ì…˜ë³´ë‹¤ ì •í™•ë„ê°€ ë†’ìœ¼ë©°, íŠ¹íˆ í•œêµ­ì–´ì™€ ê°™ì€ ë¹„ì˜ì–´ê¶Œ ì–¸ì–´ì—ì„œë„ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤. ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì–¸ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ì‘ì—…ì„ ê°„ë‹¨í•œ API í˜¸ì¶œë¡œ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.\n\n\n::: callout-note\n### ì‚¬ìš© ê°€ëŠ¥í•œ ìŒì„± ëª¨ë¸\n\nOpenAI APIë¥¼ í†µí•´ í˜„ì¬ ë‹¤ìŒ ëª¨ë¸ì„ ì œê³µí•˜ê³  ìˆë‹¤.\n\n-   `whisper-1`: OpenAI APIì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ í‘œì¤€ Whisper ëª¨ë¸ (large-v2 ê¸°ë°˜)\n-   ê°€ê²©: \\$0.006/ë¶„\n-   ë‹¤êµ­ì–´ ì§€ì›\n-   ìŒì„± ì¸ì‹ ë° ë²ˆì—­ ì§€ì›\n\n:::\n\n\n### ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜\n\nìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” STT(Speech-to-Text) ê¸°ëŠ¥ì€ íŒŸìºìŠ¤íŠ¸ ìë§‰ ìƒì„±, íšŒì˜ë¡ ì‘ì„±, ìŒì„± ëª…ë ¹ ì²˜ë¦¬ ë“± ë‹¤ì–‘í•œ ìš©ë„ë¡œ í™œìš©ëœë‹¤. Whisper ëª¨ë¸ì€ ë°°ê²½ ì†ŒìŒì´ ìˆëŠ” í™˜ê²½ì—ì„œë„ ë†’ì€ ì •í™•ë„ë¥¼ ìœ ì§€í•˜ë©°, í•œêµ­ì–´ì˜ ë³µì¡í•œ ìŒì„± ë³€í™”ë„ ì˜ ì²˜ë¦¬í•œë‹¤. [AI Hub](https://www.aihub.or.kr/) ì›¹ì‚¬ì´íŠ¸ì—ì„œ [í•œêµ­ì–´ ìŒì„±](https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=123) [@aihub2025korean] ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œ ë°›ì•„ STTë¥¼ ì‹¤ìŠµí•œë‹¤.\n\n\n::: {.cell}\n\n```{.r .cell-code .code-overflow-wrap}\nlibrary(av)\nlibrary(embedr)\n\nembedr::embed_audio(\"data/KsponSpeech_025980.mp3\")\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<audio controls> <source src='data/KsponSpeech_025980.mp3' type='audio/mpeg'> Your browser does not support the audio tag;  for browser support, please see:  https://www.w3schools.com/tags/tag_audio.asp </audio>\n```\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.python .cell-code .code-overflow-wrap}\n# ìŒì„± íŒŒì¼ ì—´ê¸°\nwith open(\"data/KsponSpeech_025980.mp3\", \"rb\") as audio_file:\n    response = client.audio.transcriptions.create(\n        model=\"whisper-1\",\n        file=audio_file,\n        language=\"ko\",  # í•œêµ­ì–´ ì§€ì •\n        response_format=\"text\"  # text, json, srt, verbose_json, vtt ì¤‘ ì„ íƒ\n    )\n\n# ë³€í™˜ëœ í…ìŠ¤íŠ¸ ì €ì¥\nwith open(\"data/KsponSpeech_025980.txt\", \"w\", encoding=\"utf-8\") as f:\n    f.write(response)\n```\n:::\n\n\n::: {layout-ncol=\"2\"}\n#### TTS ì¶œë ¥ê²°ê³¼ {.unnumbered}\n\n``` markdown\n'ì˜¤íˆë ¤ ë‚´ê°€ ë˜ ì•ˆì˜¬ë¼ê°„ ì´ìœ  ì¤‘ì— í•˜ë‚˜ê°€\\n'\n```\n\n#### ì›ë³¸ {.unnumbered}\n\n``` markdown\nì˜¤íˆë ¤ ë‚´ê°€ ë˜ ì•ˆì˜¬ë¼ê°„ ì´ìœ  ì¤‘ì— í•˜ë‚˜ê°€\\n\n```\n:::\n\n### ìŒì„± ë²ˆì—­\n\nìŒì„± ë²ˆì—­ ê¸°ëŠ¥ì€ ìŒì„± ì¸ì‹ê³¼ ë²ˆì—­ì„ í•œ ë²ˆì— ì²˜ë¦¬í•˜ëŠ” íš¨ìœ¨ì ì¸ ì†”ë£¨ì…˜ì´ë‹¤. ë‹¤êµ­ì–´ íšŒì˜ë‚˜ êµ­ì œ ê°•ì—°ì—ì„œ ì‹¤ì‹œê°„ ë²ˆì—­ì´ í•„ìš”í•  ë•Œ ìœ ìš©í•˜ë©°, ì›ë³¸ ì–¸ì–´ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•œ í›„ ë²ˆì—­í•˜ëŠ” 2ë‹¨ê³„ ê³¼ì •ì„ 1ë‹¨ê³„ë¡œ ë‹¨ì¶•ì‹œí‚¨ë‹¤. Whisper API [@openai2025whisper]ëŠ” ë‹¤ì–‘í•œ ì–¸ì–´ì˜ ìŒì„±ì„ ì˜ì–´ë¡œ ë²ˆì—­í•  ìˆ˜ ìˆë‹¤:\n\n\n::: {.cell}\n\n```{.python .cell-code .code-overflow-wrap}\nwith open(\"data/á„Œá…¦84á„Œá…®á„‚á…§á†«_31á„Œá…¥á†¯_á„€á…µá„‚á…§á†·á„‰á…¡_á„‚á…©á„†á…®á„’á…§á†«.mp3\", \"rb\") as audio_file:\n    response = client.audio.translations.create(\n        model=\"whisper-1\",\n        file=audio_file,\n        prompt=\"í•œêµ­ ëŒ€í†µë ¹ì˜ ì—°ì„¤ì…ë‹ˆë‹¤.\"  # ì»¨í…ìŠ¤íŠ¸ ì œê³µìœ¼ë¡œ ì •í™•ë„ í–¥ìƒ\n    )\n\nprint(response.text)\n```\n:::\n\n\n``` markdown\nHonorable citizens, On the 84th anniversary of the Korean War, I express my deep gratitude and respect to the patriots who sacrificed for the country. \n\n... ì¤‘ëµ\n\nLet us open the East-West era of peace and prosperity through unification and reform. Let us pass on the proud Republic of Korea to our descendants. Thank you. Thank you.\n```\n\n## ì´ë¯¸ì§€ ìƒì„±\n\ní…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œë¶€í„° ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” DALLÂ·E APIëŠ” ì°½ì‘ í™œë™ì˜ ìƒˆë¡œìš´ ì§€í‰ì„ ì—´ì–´ì£¼ëŠ” í˜ì‹ ì ì¸ ë„êµ¬ë‹¤. ë””ìì¸ ì‹œì•ˆ ì‘ì„±, ì½˜í…ì¸  ì œì‘, êµìœ¡ ìë£Œ ê°œë°œ ë“±ì—ì„œ ì‹œê°„ê³¼ ë¹„ìš©ì„ í¬ê²Œ ì ˆì•½í•  ìˆ˜ ìˆë‹¤. íŠ¹íˆ DALLÂ·E 3ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ìµœì í™”í•˜ì—¬ ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ ë” ì •í™•í•˜ê²Œ ë°˜ì˜í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•œë‹¤. DALLÂ·E API [@openai2025dalle]ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œë¶€í„° ê³ í’ˆì§ˆ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ìˆë‹¤.\n\n::: callout-note\n\n### ì‚¬ìš© ê°€ëŠ¥í•œ ì´ë¯¸ì§€ ëª¨ë¸\n\n-   `dall-e-3`: ìµœì‹  ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ (ê³ í’ˆì§ˆ, í”„ë¡¬í”„íŠ¸ ìµœì í™” í¬í•¨)\n-   `dall-e-2`: ì´ì „ ë²„ì „ (ë” ë¹ ë¥´ê³  ì €ë ´)\n-   `gpt-4o`: ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ (í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ í†µí•© ì´í•´, ì œí•œì  ì ‘ê·¼)\n\n:::\n\n### ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„±\n\nì´ë¯¸ì§€ ìƒì„± ì‹œ í”„ë¡¬í”„íŠ¸ì˜ êµ¬ì²´ì„±ê³¼ ëª…í™•ì„±ì´ ê²°ê³¼ë¬¼ì˜ í’ˆì§ˆì„ í¬ê²Œ ì¢Œìš°í•œë‹¤. ìŠ¤íƒ€ì¼, ìƒ‰ìƒ, êµ¬ë„, ë¶„ìœ„ê¸° ë“±ì„ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œí• ìˆ˜ë¡ ì›í•˜ëŠ” ê²°ê³¼ë¥¼ ì–»ì„ ê°€ëŠ¥ì„±ì´ ë†’ì•„ì§„ë‹¤.\n\n\n::: {.cell}\n\n```{.python .cell-code .code-overflow-wrap}\nresponse = client.images.generate(\n    model=\"dall-e-3\",  # ë˜ëŠ” \"dall-e-2\"\n    prompt=\"ì„œìš¸ ê°•ë‚¨ ê±°ë¦¬, ì—¬ë¦„ë‚ , ë°ê³  ì•„ë¦„ë‹¤ìš´ í’ê²½, ì˜í™”ì ì¸ ì¥ë©´ ì§€ë¸Œë¦¬ ìŠ¤íƒ€ì¼\",\n    size=\"1024x1024\",  # DALL-E 3: 1024x1024, 1792x1024, 1024x1792\n    quality=\"standard\",  # \"standard\" ë˜ëŠ” \"hd\"\n    style=\"vivid\",  # \"vivid\" ë˜ëŠ” \"natural\"\n    n=1  # DALL-E 3ëŠ” n=1ë§Œ ì§€ì›\n)\n\n# ìƒì„±ëœ ì´ë¯¸ì§€ URL í™•ì¸\nimage_url = response.data[0].url\nprint(f\"ìƒì„±ëœ ì´ë¯¸ì§€ URL: {image_url}\")\n\n# ìˆ˜ì •ëœ í”„ë¡¬í”„íŠ¸ í™•ì¸ (DALL-E 3ì˜ í”„ë¡¬í”„íŠ¸ ìµœì í™”)\nrevised_prompt = response.data[0].revised_prompt\nprint(f\"ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸: {revised_prompt}\")\n\n# ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ì €ì¥\nimport requests\nfrom PIL import Image\nimport io\n\n# URLì€ ì„ì‹œì ì´ë¯€ë¡œ ì¦‰ì‹œ ë‹¤ìš´ë¡œë“œ ê¶Œì¥\nimg_response = requests.get(image_url)\nimage = Image.open(io.BytesIO(img_response.content))\nimage.save('images/gangnam_image.png', 'PNG')\n```\n:::\n\n\n![ê°•ë‚¨ê±°ë¦¬ ì§€ë¸Œë¦¬ ìŠ¤íƒ€ì¼ë¡œ ìƒì„±ëœ ì´ë¯¸ì§€](images/gangnam_image.png){#fig-dalle-gangnam fig-align=\"center\" width=\"200\"}\n\n### DALLÂ·E 3 ì˜µì…˜\n\nDALLÂ·E 3ì˜ ë‹¤ì–‘í•œ ì˜µì…˜ë“¤ì„ ì ì ˆíˆ ì¡°í•©í•˜ë©´ ìš©ë„ì— ë§ëŠ” ìµœì ì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ìˆë‹¤. í¬ê¸°ëŠ” ì‚¬ìš© ëª©ì ì— ë”°ë¼, í’ˆì§ˆì€ ì˜ˆì‚°ê³¼ ìš”êµ¬ì‚¬í•­ì— ë”°ë¼, ìŠ¤íƒ€ì¼ì€ ë¸Œëœë“œë‚˜ ì½˜í…ì¸  ì„±ê²©ì— ë§ì¶° ì„ íƒí•œë‹¤.\n\n**ì´ë¯¸ì§€ í¬ê¸° ì„¤ì •**ì€ ìµœì¢… ìš©ë„ë¥¼ ê³ ë ¤í•˜ì—¬ ê²°ì •í•´ì•¼ í•œë‹¤. DALLÂ·E 3ëŠ” ì„¸ ê°€ì§€ í•´ìƒë„ë¥¼ ì§€ì›í•˜ë©°, ì •ì‚¬ê°í˜•(1024x1024)ì€ ì†Œì…œ ë¯¸ë””ì–´ í”„ë¡œí•„ì´ë‚˜ ì•„ì´ì½˜ì— ì í•©í•˜ê³  ì²˜ë¦¬ ì†ë„ê°€ ê°€ì¥ ë¹ ë¥´ë‹¤. ê°€ë¡œí˜•(1792x1024)ì€ ì›¹ì‚¬ì´íŠ¸ ë°°ë„ˆë‚˜ í”„ë ˆì  í…Œì´ì…˜ ìŠ¬ë¼ì´ë“œì— ì´ìƒì ì´ë©°, ì„¸ë¡œí˜•(1024x1792)ì€ ëª¨ë°”ì¼ í™”ë©´ì´ë‚˜ í¬ìŠ¤í„° ì œì‘ì— ìœ ìš©í•˜ë‹¤. DALLÂ·E 2ì˜ ê²½ìš° 256x256ë¶€í„° 1024x1024ê¹Œì§€ ë‹¤ì–‘í•œ í¬ê¸°ë¥¼ ì œê³µí•˜ì§€ë§Œ, í’ˆì§ˆ ë©´ì—ì„œëŠ” DALLÂ·E 3ì— ë¹„í•´ ì œí•œì ì´ë‹¤.\n\n**í’ˆì§ˆ ì˜µì…˜**ì€ ë¹„ìš©ê³¼ ê²°ê³¼ë¬¼ì˜ ì™„ì„±ë„ ì‚¬ì´ì˜ ê· í˜•ì„ ë§ì¶”ëŠ” ì¤‘ìš”í•œ ìš”ì†Œë‹¤. í‘œì¤€ í’ˆì§ˆ(standard)ì€ ì¼ë°˜ì ì¸ ìš©ë„ì— ì¶©ë¶„í•˜ë©° ë¹ ë¥¸ ì²˜ë¦¬ì™€ ì €ë ´í•œ ë¹„ìš©ì´ ì¥ì ì´ë‹¤. ê³ í’ˆì§ˆ(hd) ì˜µì…˜ì€ ì„¸ë¶€ì‚¬í•­ì˜ ì •ë°€ë„ë¥¼ ë†’ì´ê³  ì´ë¯¸ì§€ ì „ì²´ì˜ ì¼ê´€ì„±ì„ ê°œì„ í•˜ì—¬ ì „ë¬¸ì ì¸ ìš©ë„ë‚˜ ì¸ì‡„ë¬¼ ì œì‘ ì‹œ ê¶Œì¥ëœë‹¤. ë¹„ìš©ì€ ì•½ 2ë°° ì°¨ì´ê°€ ë‚˜ë¯€ë¡œ í”„ë¡œì íŠ¸ì˜ ìš”êµ¬ì‚¬í•­ê³¼ ì˜ˆì‚°ì„ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•´ì•¼ í•œë‹¤.\n\n**ìŠ¤íƒ€ì¼ ì„¤ì •**ì€ ì´ë¯¸ì§€ì˜ ì „ë°˜ì ì¸ ë¶„ìœ„ê¸°ì™€ í‘œí˜„ ë°©ì‹ì„ ê²°ì •í•œë‹¤. ìƒìƒí•œ(vivid) ìŠ¤íƒ€ì¼ì€ ì±„ë„ê°€ ë†’ê³  ëŒ€ë¹„ê°€ ê°•í•œ ì˜í™”ì  í‘œí˜„ì„ ì œê³µí•˜ì—¬ ì‹œê°ì  ì„íŒ©íŠ¸ê°€ í° ë§ˆì¼€íŒ… ìë£Œë‚˜ ì°½ì‘ë¬¼ì— ì í•©í•˜ë‹¤. ìì—°ìŠ¤ëŸ¬ìš´(natural) ìŠ¤íƒ€ì¼ì€ ì‚¬ì‹¤ì ì´ê³  ì ˆì œëœ í‘œí˜„ìœ¼ë¡œ êµìœ¡ ìë£Œë‚˜ ê¸°ìˆ  ë¬¸ì„œì—ì„œ ë” ì ì ˆí•˜ë‹¤. ë¸Œëœë“œ ê°€ì´ë“œë¼ì¸ì´ë‚˜ ì½˜í…ì¸ ì˜ ì„±ê²©ì— ë”°ë¼ ì¼ê´€ëœ ìŠ¤íƒ€ì¼ì„ ìœ ì§€í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤.\n\n::: callout-note\n### ì‚¬ìš© ì œí•œì‚¬í•­\n\nì œí•œì‚¬í•­ë“¤ì„ ë¯¸ë¦¬ íŒŒì•…í•˜ê³  ê³„íší•˜ë©´ í”„ë¡œì íŠ¸ ì§„í–‰ ì‹œ ì˜ˆìƒì¹˜ ëª»í•œ ë¬¸ì œë¥¼ ë°©ì§€í•  ìˆ˜ ìˆë‹¤. íŠ¹íˆ ëŒ€ëŸ‰ì˜ ì´ë¯¸ì§€ê°€ í•„ìš”í•œ í”„ë¡œì íŠ¸ì—ì„œëŠ” ì†ë„ ì œí•œì„ ê³ ë ¤í•œ ì¼ì • ê³„íšì´ í•„ìš”í•˜ë‹¤.\n\n-   **ì†ë„ ì œí•œ**: í‘œì¤€ ê³„ì •ì€ ë¶„ë‹¹ 5ê°œ ìš”ì²­\n-   **ì´ë¯¸ì§€ ìˆ˜**: DALL-E 3ëŠ” í•œ ë²ˆì— 1ê°œ ì´ë¯¸ì§€ë§Œ ìƒì„± (n=1)\n-   **ì„ì‹œ ì €ì¥**: ìƒì„±ëœ ì´ë¯¸ì§€ URLì€ ì„ì‹œì ì´ë¯€ë¡œ ì¦‰ì‹œ ë‹¤ìš´ë¡œë“œ í•„ìš”\n-   **í¸ì§‘ ë¶ˆê°€**: DALL-E 3ëŠ” ì´ë¯¸ì§€ í¸ì§‘ì´ë‚˜ ë³€í˜• API ë¯¸ì§€ì›\n\n:::\n\nBase64 ì¸ì½”ë”© ë°©ì‹ì€ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì§ì ‘ ë°›ì•„ì˜¬ ìˆ˜ ìˆì–´ URL ë§Œë£Œ ê±±ì • ì—†ì´ ì•ˆì •ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤. íŠ¹íˆ ì„œë²„ í™˜ê²½ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì¦‰ì‹œ ì²˜ë¦¬í•˜ê³  ì €ì¥í•´ì•¼ í•  ë•Œ ìœ ìš©í•˜ë‹¤.\n\n\n::: {.cell}\n\n```{.python .cell-code .code-overflow-wrap}\n# Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ë¡œ ë°›ê¸°\nresponse_format = \"b64_json\" \n\nresponse = client.images.generate(\n    model=\"dall-e-3\",\n    prompt=\"ì•„ë¦„ë‹¤ìš´ í•œêµ­ ì „í†µ í•œì˜¥\",\n    response_format=response_format\n)\n\n# Base64 ë°ì´í„°ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜\nimport base64\nfrom io import BytesIO\n\nif response_format == \"b64_json\":\n    image_data = base64.b64decode(response.data[0].b64_json)\n    image = Image.open(BytesIO(image_data))\n    image.save('images/hanok.png')\n\n```\n:::\n\n\n![ì‘ë‹µí˜•ì‹ì„ Base64 ë°ì´í„°ë¡œ ìƒì„±ëœ ì´ë¯¸ì§€](images/hanok.png){#fig-dalle-hanok fig-align=\"center\" width=\"200\"}\n\n\n\n## ì„ë² ë”©\n\ní…ìŠ¤íŠ¸ ì„ë² ë”©ì€ ìì—°ì–´ë¥¼ ìˆ˜ì¹˜ì  ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ì»´í“¨í„°ê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë§Œë“œëŠ” í•µì‹¬ ê¸°ìˆ ì´ë‹¤. ë¬¸ì„œ ê²€ìƒ‰, ì¶”ì²œ ì‹œìŠ¤í…œ, ê°ì • ë¶„ì„, í´ëŸ¬ìŠ¤í„°ë§ ë“± ë‹¤ì–‘í•œ AI ì‘ìš©ì—ì„œ ê¸°ë°˜ ê¸°ìˆ ë¡œ í™œìš©ëœë‹¤. ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ í…ìŠ¤íŠ¸ë“¤ì€ ë²¡í„° ê³µê°„ì—ì„œë„ ê°€ê¹Œìš´ ìœ„ì¹˜ì— ë°°ì¹˜ë˜ì–´ ìœ ì‚¬ë„ ì¸¡ì •ì´ ê°€ëŠ¥í•˜ë‹¤. OpenAI Embeddings API [@openai2025embeddings]ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ê³ ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜í•  ìˆ˜ ìˆë‹¤.\n\n::: callout-note\n### ì‚¬ìš© ê°€ëŠ¥í•œ ì„ë² ë”© ëª¨ë¸\n\n- `text-embedding-3-large`: ìµœê³  ì„±ëŠ¥ ëª¨ë¸ (3072ì°¨ì›, $0.00013/1K í† í°)\n- `text-embedding-3-small`: íš¨ìœ¨ì ì´ê³  ë¹„ìš© íš¨ê³¼ì  (1536ì°¨ì›, ë¹ ë¥¸ ì²˜ë¦¬)\n- `text-embedding-ada-002`: ì´ì „ ëª¨ë¸ (1536ì°¨ì›, í˜¸í™˜ì„± ëª©ì )\n\n:::\n\n### ê¸°ë³¸ ì„ë² ë”© ìƒì„±\n\nì„ë² ë”© ìƒì„±ì˜ í•µì‹¬ì€ ì ì ˆí•œ ëª¨ë¸ ì„ íƒê³¼ ì¼ê´€ëœ ì²˜ë¦¬ ë°©ì‹ì´ë‹¤. í”„ë¡œì íŠ¸ ì „ì²´ì—ì„œ ë™ì¼í•œ ëª¨ë¸ì„ ì‚¬ìš©í•´ì•¼ ë²¡í„° ê°„ ë¹„êµê°€ ì˜ë¯¸ ìˆëŠ” ê²°ê³¼ë¥¼ ì œê³µí•œë‹¤.\n\n\n::: {.cell}\n\n```{.python .cell-code .code-overflow-wrap}\n# í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± í•¨ìˆ˜\ndef get_embedding(text, model=\"text-embedding-3-large\"):\n    response = client.embeddings.create(\n        input=text,\n        model=model\n    )\n    return response.data[0].embedding\n\n# ì˜ˆì œ: ë„ì‹œ ì´ë¦„ ì„ë² ë”©\nseoul_embedding = get_embedding(\"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.\")\ntokyo_embedding = get_embedding(\"ì¼ë³¸ì˜ ìˆ˜ë„ëŠ” ë„ì¿„ì…ë‹ˆë‹¤.\")\nparis_embedding = get_embedding(\"í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ëŠ” íŒŒë¦¬ì…ë‹ˆë‹¤.\")\n\nprint(f\"ë²¡í„° ì°¨ì›: {len(seoul_embedding)}\")  # 3072ì°¨ì› (text-embedding-3-large)\n\n# ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\nimport numpy as np\n\ndef cosine_similarity(a, b):\n    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n\n# ì„œìš¸-ë„ì¿„ ìœ ì‚¬ë„\nsimilarity_seoul_tokyo = cosine_similarity(seoul_embedding, tokyo_embedding)\nprint(f\"ì„œìš¸-ë„ì¿„ ìœ ì‚¬ë„: {similarity_seoul_tokyo:.4f}\")\n\n# ì„œìš¸-íŒŒë¦¬ ìœ ì‚¬ë„\nsimilarity_seoul_paris = cosine_similarity(seoul_embedding, paris_embedding)\nprint(f\"ì„œìš¸-íŒŒë¦¬ ìœ ì‚¬ë„: {similarity_seoul_paris:.4f}\")\n```\n:::\n\n\n```markdown\në²¡í„° ì°¨ì›: 3072\nì„œìš¸-ë„ì¿„ ìœ ì‚¬ë„: 0.5272\nì„œìš¸-íŒŒë¦¬ ìœ ì‚¬ë„: 0.5015\n```\n\n### ì°¨ì› ì¶•ì†Œ ê¸°ëŠ¥\n\nMatryoshka Representation Learning ê¸°ìˆ ì„ í™œìš©í•œ ì°¨ì› ì¶•ì†ŒëŠ” ì €ì¥ ê³µê°„ê³¼ ê³„ì‚° ë¹„ìš©ì„ í¬ê²Œ ì ˆì•½í•˜ë©´ì„œë„ ì„±ëŠ¥ ì†ì‹¤ì„ ìµœì†Œí™”í•˜ëŠ” í˜ì‹ ì ì¸ ê¸°ëŠ¥ì´ë‹¤. ëŒ€ê·œëª¨ ë¬¸ì„œ ì»¬ë ‰ì…˜ì„ ë‹¤ë£° ë•Œ íŠ¹íˆ ìœ ìš©í•˜ë©°, ë©”ëª¨ë¦¬ ì œì•½ì´ ìˆëŠ” í™˜ê²½ì—ì„œë„ íš¨ê³¼ì ìœ¼ë¡œ ì„ë² ë”©ì„ í™œìš©í•  ìˆ˜ ìˆë‹¤. ìƒˆë¡œìš´ ì„ë² ë”© ëª¨ë¸ì€ ì°¨ì›ì„ ì¤„ì—¬ë„ ì„±ëŠ¥ì´ í¬ê²Œ ë–¨ì–´ì§€ì§€ ì•ŠëŠ”ë‹¤:\n\n\n::: {.cell}\n\n```{.python .cell-code .code-overflow-wrap}\n# ì°¨ì› ì¶•ì†Œ ì„ë² ë”© ìƒì„±\ndef get_embedding_with_dimensions(text, dimensions=1024):\n    response = client.embeddings.create(\n        input=text,\n        model=\"text-embedding-3-large\",\n        dimensions=dimensions  # 256, 512, 1024, 2048 ë“± ì„ íƒ ê°€ëŠ¥\n    )\n    return response.data[0].embedding\n\n# ì°¨ì›ë³„ ì„±ëŠ¥ ë¹„êµ\ntext = \"ì¸ê³µì§€ëŠ¥ê³¼ ë¨¸ì‹ ëŸ¬ë‹ì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n\n# í’€ ì‚¬ì´ì¦ˆ (3072ì°¨ì›)\nfull_embedding = get_embedding(text, \"text-embedding-3-large\")\nprint(f\"í’€ ì‚¬ì´ì¦ˆ: {len(full_embedding)}ì°¨ì›\")\n\n# ì¶•ì†Œëœ ì‚¬ì´ì¦ˆ (1024ì°¨ì›)\nreduced_embedding = get_embedding_with_dimensions(text, 1024)\nprint(f\"ì¶•ì†Œ ì‚¬ì´ì¦ˆ: {len(reduced_embedding)}ì°¨ì›\")\n\n# ì €ì¥ ê³µê°„ 14ë°° ì ˆì•½, ì„±ëŠ¥ì€ ê±°ì˜ ë™ì¼\n```\n:::\n\n\n```markdown\ní’€ ì‚¬ì´ì¦ˆ: 3072ì°¨ì›\nì¶•ì†Œ ì‚¬ì´ì¦ˆ: 1024ì°¨ì›\n```\n\n### ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ\n\nê° ëª¨ë¸ì€ ì„±ëŠ¥ê³¼ ë¹„ìš© ì¸¡ë©´ì—ì„œ ê³ ìœ í•œ íŠ¹ì„±ì„ ê°€ì§€ê³  ìˆì–´, í”„ë¡œì íŠ¸ì˜ ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” ì„ íƒì´ ì¤‘ìš”í•˜ë‹¤. ë†’ì€ ì •í™•ë„ê°€ í•„ìš”í•œ í•µì‹¬ ê¸°ëŠ¥ì—ëŠ” large ëª¨ë¸ì„, ëŒ€ëŸ‰ ì²˜ë¦¬ê°€ í•„ìš”í•œ ë°°ì¹˜ ì‘ì—…ì—ëŠ” small ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ íš¨ìœ¨ì ì´ë‹¤.\n\n\n::: {.cell}\n\n```{.python .cell-code .code-overflow-wrap}\n# ëª¨ë¸ë³„ ì„±ëŠ¥ ë° ë¹„ìš© ë¹„êµ\nmodels = [\n    {\"name\": \"text-embedding-3-large\", \"dimensions\": 3072, \"price\": 0.00013},\n    {\"name\": \"text-embedding-3-small\", \"dimensions\": 1536, \"price\": 0.00002},\n    {\"name\": \"text-embedding-ada-002\", \"dimensions\": 1536, \"price\": 0.0001}\n]\n\ntest_text = \"ìì—°ì–´ ì²˜ë¦¬ì™€ ì»´í“¨í„° ë¹„ì „ì˜ ì‘ìš© ë¶„ì•¼\"\n\nfor model in models:\n    embedding = get_embedding(test_text, model[\"name\"])\n    print(f\"ëª¨ë¸: {model['name']}\")\n    print(f\"ì°¨ì›ìˆ˜: {len(embedding)}\")\n    print(f\"ê°€ê²©: ${model['price']}/1K í† í°\")\n    print(\"---\")\n```\n:::\n\n\n```markdown\nëª¨ë¸: text-embedding-3-large\nì°¨ì›ìˆ˜: 3072\nê°€ê²©: $0.00013/1K í† í°\n---\nëª¨ë¸: text-embedding-3-small\nì°¨ì›ìˆ˜: 1536\nê°€ê²©: $2e-05/1K í† í°\n---\nëª¨ë¸: text-embedding-ada-002\nì°¨ì›ìˆ˜: 1536\nê°€ê²©: $0.0001/1K í† í°\n---\n```\n\n### ì‹¤ìš©ì ì¸ ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹œìŠ¤í…œ\n\nì‹¤ì œ ì‘ìš©ì—ì„œëŠ” ë‹¨ìˆœí•œ ì„ë² ë”© ìƒì„±ì„ ë„˜ì–´ì„œ ì²´ê³„ì ì¸ ê²€ìƒ‰ ì‹œìŠ¤í…œ êµ¬ì¶•ì´ í•„ìš”í•˜ë‹¤. ë¬¸ì„œë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì¸ë±ì‹±í•˜ì—¬ ë¹ ë¥¸ ê²€ìƒ‰ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ë©°, ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ í†µí•´ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œë¥¼ ìˆœì„œëŒ€ë¡œ ì œê³µí•œë‹¤.\n\n\n::: {.cell}\n\n```{.python .cell-code .code-overflow-wrap}\n# ë¬¸ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹œìŠ¤í…œ\nimport pandas as pd\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ndef build_document_search_system(documents):\n    \"\"\"ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ê²€ìƒ‰ ì‹œìŠ¤í…œ êµ¬ì¶•\"\"\"\n    embeddings = []\n    for doc in documents:\n        embedding = get_embedding(doc, \"text-embedding-3-small\")\n        embeddings.append(embedding)\n    \n    return pd.DataFrame({\n        'document': documents,\n        'embedding': embeddings\n    })\n\ndef search_similar_documents(query, doc_df, top_k=3):\n    \"\"\"ì¿¼ë¦¬ì™€ ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œë“¤ ê²€ìƒ‰\"\"\"\n    query_embedding = get_embedding(query, \"text-embedding-3-small\")\n    \n    # ëª¨ë“  ë¬¸ì„œì™€ì˜ ìœ ì‚¬ë„ ê³„ì‚°\n    similarities = []\n    for embedding in doc_df['embedding']:\n        similarity = cosine_similarity([query_embedding], [embedding])[0][0]\n        similarities.append(similarity)\n    \n    doc_df['similarity'] = similarities\n    return doc_df.nlargest(top_k, 'similarity')\n\n# ì‚¬ìš© ì˜ˆì œ\ndocuments = [\n    \"íŒŒì´ì¬ì€ ë°ì´í„° ë¶„ì„ì— ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤.\",\n    \"ë¨¸ì‹ ëŸ¬ë‹ì€ ì¸ê³µì§€ëŠ¥ì˜ í•œ ë¶„ì•¼ë¡œ ë°ì´í„°ë¡œë¶€í„° íŒ¨í„´ì„ í•™ìŠµí•©ë‹ˆë‹¤.\",\n    \"ìì—°ì–´ ì²˜ë¦¬ëŠ” ì»´í“¨í„°ê°€ ì¸ê°„ì˜ ì–¸ì–´ë¥¼ ì´í•´í•˜ë„ë¡ í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\",\n    \"ë”¥ëŸ¬ë‹ì€ ì‹ ê²½ë§ì„ ì´ìš©í•œ ë¨¸ì‹ ëŸ¬ë‹ì˜ í•œ ë°©ë²•ì…ë‹ˆë‹¤.\"\n]\n\ndoc_system = build_document_search_system(documents)\nresults = search_similar_documents(\"AIì™€ ë°ì´í„° ê³¼í•™\", doc_system)\nprint(results[['document', 'similarity']])\n```\n:::\n\n\n```markdown\n                               document  similarity\n0     íŒŒì´ì¬ì€ ë°ì´í„° ë¶„ì„ì— ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤.    0.417869\n1   ë¨¸ì‹ ëŸ¬ë‹ì€ ì¸ê³µì§€ëŠ¥ì˜ í•œ ë¶„ì•¼ë¡œ ë°ì´í„°ë¡œë¶€í„° íŒ¨í„´ì„ í•™ìŠµí•©ë‹ˆë‹¤.    0.395203\n2  ìì—°ì–´ ì²˜ë¦¬ëŠ” ì»´í“¨í„°ê°€ ì¸ê°„ì˜ ì–¸ì–´ë¥¼ ì´í•´í•˜ë„ë¡ í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.    0.263060\n```\n\n## ì½˜í…ì¸  ì¤‘ì¬\n\nì˜¨ë¼ì¸ í”Œë«í¼ê³¼ ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ì•ˆì „í•œ í™˜ê²½ì„ ìœ ì§€í•˜ëŠ” ê²ƒì€ í•„ìˆ˜ì ì¸ ìš”êµ¬ì‚¬í•­ì´ë‹¤. ìˆ˜ë™ìœ¼ë¡œ ëª¨ë“  ì½˜í…ì¸ ë¥¼ ê²€í† í•˜ëŠ” ê²ƒì€ í˜„ì‹¤ì ìœ¼ë¡œ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ, AI ê¸°ë°˜ ìë™ ì¤‘ì¬ ì‹œìŠ¤í…œì´ ì¤‘ìš”í•œ ì—­í• ì„ í•œë‹¤. OpenAIì˜ ì¤‘ì¬ APIëŠ” í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ëª¨ë‘ ì²˜ë¦¬í•  ìˆ˜ ìˆì–´ ì¢…í•©ì ì¸ ì½˜í…ì¸  ì•ˆì „ ê´€ë¦¬ê°€ ê°€ëŠ¥í•˜ë‹¤. OpenAI Moderation API [@openai2025moderation]ëŠ” ì½˜í…ì¸ ì˜ ì•ˆì „ì„±ì„ ê²€ì‚¬í•˜ì—¬ ìœ í•´í•œ ë‚´ìš©ì„ íƒì§€í•œë‹¤.\n\n### ì¤‘ì¬ ëª¨ë¸ê³¼ íƒì§€ ì‹œìŠ¤í…œ\n\nOpenAIì˜ ì½˜í…ì¸  ì¤‘ì¬ ì‹œìŠ¤í…œì€ 2025ë…„ GPT-4o ê¸°ë°˜ìœ¼ë¡œ ì™„ì „íˆ ìƒˆë¡­ê²Œ ê°œí¸ë˜ì–´ ì´ì „ ë²„ì „ë³´ë‹¤ í¬ê²Œ í–¥ìƒëœ ì„±ëŠ¥ì„ ì œê³µí•œë‹¤. ì´ ì‹œìŠ¤í…œì€ ë‹¨ìˆœí•œ í‚¤ì›Œë“œ í•„í„°ë§ì„ ë„˜ì–´ì„œ ë§¥ë½ì„ ì´í•´í•˜ëŠ” AI ê¸°ë°˜ ì ‘ê·¼ë²•ì„ ì‚¬ìš©í•˜ì—¬ ë”ìš± ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì½˜í…ì¸  ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•œë‹¤. ê°€ì¥ ì£¼ëª©í•  ë§Œí•œ ê°œì„ ì‚¬í•­ì€ ë©€í‹°ëª¨ë‹¬ ì§€ì›ìœ¼ë¡œ, í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ë™ì‹œì— ì²˜ë¦¬í•  ìˆ˜ ìˆì–´ ì¢…í•©ì ì¸ ì½˜í…ì¸  ì•ˆì „ ê´€ë¦¬ê°€ ê°€ëŠ¥í•´ì¡Œë‹¤.\n\nì‹œìŠ¤í…œì€ 8ê°€ì§€ ì£¼ìš” ì¹´í…Œê³ ë¦¬ë¡œ ìœ í•´ ì½˜í…ì¸ ë¥¼ ë¶„ë¥˜í•œë‹¤. ê¸°ì¡´ì˜ ì¦ì˜¤ í‘œí˜„(`hate`), ê´´ë¡­í˜(`harassment`), ìí•´(`self-harm`), ì„±ì  ì½˜í…ì¸ (`sexual`), í­ë ¥(`violence`, `violence/graphic`) ì¹´í…Œê³ ë¦¬ì— ë”í•´, 2025ë…„ì—ëŠ” ë¶ˆë²• í–‰ìœ„ ê´€ë ¨ ì¹´í…Œê³ ë¦¬(`illicit`, `illicit/violent`)ê°€ ìƒˆë¡­ê²Œ ì¶”ê°€ë˜ì—ˆë‹¤. ì´ëŸ¬í•œ ì¹´í…Œê³ ë¦¬ í™•ì¥ì€ ë²•ì  ë¦¬ìŠ¤í¬ ë°©ì§€ì™€ ë” í¬ê´„ì ì¸ ì•ˆì „ ê´€ë¦¬ë¥¼ ìœ„í•œ í•„ìˆ˜ì ì¸ ë°œì „ì´ë‹¤. ê° ì¹´í…Œê³ ë¦¬ëŠ” 0ê³¼ 1 ì‚¬ì´ì˜ ì ìˆ˜ë¡œ ìœ„í—˜ë„ë¥¼ ì œê³µí•˜ì—¬ ê°œë°œìê°€ ìì‹ ì˜ í”Œë«í¼ì— ë§ëŠ” ì„ê³„ê°’ì„ ì„¤ì •í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•œë‹¤.\n\në‹¤êµ­ì–´ ì§€ì› ì—­ì‹œ í¬ê²Œ ê°œì„ ë˜ì–´ 40ê°œ ì–¸ì–´ì—ì„œ í‰ê·  42%ì˜ ì„±ëŠ¥ í–¥ìƒì„ ë‹¬ì„±í–ˆë‹¤. ì´ëŠ” ê¸€ë¡œë²Œ ì„œë¹„ìŠ¤ ìš´ì˜ì—ì„œ ì–¸ì–´ë³„ ë¬¸í™”ì  ë§¥ë½ê³¼ í‘œí˜„ ë°©ì‹ì˜ ì°¨ì´ë¥¼ ë” ì •í™•íˆ ì´í•´í•  ìˆ˜ ìˆìŒì„ ì˜ë¯¸í•œë‹¤. íŠ¹íˆ í•œêµ­ì–´, ì¼ë³¸ì–´, ì¤‘êµ­ì–´ì™€ ê°™ì€ ì•„ì‹œì•„ ì–¸ì–´ì—ì„œì˜ ì„±ëŠ¥ ê°œì„ ì€ êµ­ë‚´ ì„œë¹„ìŠ¤ ìš´ì˜ìë“¤ì—ê²Œ í° ë„ì›€ì´ ë  ê²ƒì´ë‹¤.\n\n### í…ìŠ¤íŠ¸ ì¤‘ì¬ ì‹¤ìŠµê³¼ í™œìš©\n\ní…ìŠ¤íŠ¸ ì¤‘ì¬ëŠ” ì‹¤ì‹œê°„ ëŒ“ê¸€ ì‹œìŠ¤í…œ, ì†Œì…œ ë¯¸ë””ì–´ í”Œë«í¼, ì±„íŒ… ì• í”Œë¦¬ì¼€ì´ì…˜ ë“±ì—ì„œ í•µì‹¬ì ì¸ ì—­í• ì„ ìˆ˜í–‰í•œë‹¤. OpenAIì˜ ì¤‘ì¬ APIëŠ” ë‹¨ìˆœí•œ ì´ì§„ ë¶„ë¥˜(ì•ˆì „/ìœ„í—˜)ë¥¼ ë„˜ì–´ì„œ ê° ì¹´í…Œê³ ë¦¬ë³„ ì„¸ë°€í•œ ì ìˆ˜ë¥¼ ì œê³µí•˜ë¯€ë¡œ, í”Œë«í¼ì˜ íŠ¹ì„±ê³¼ ì •ì±…ì— ë§ëŠ” ë§ì¶¤í˜• ì¤‘ì¬ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆë‹¤.\n\nì•ˆì „í•œ ì½˜í…ì¸ ì˜ ê²½ìš° ì¼ë°˜ì ì¸ ì¼ìƒ ëŒ€í™”, êµìœ¡ì  ë‚´ìš©, ì—…ë¬´ ê´€ë ¨ ì†Œí†µ ë“±ì´ ëª¨ë“  ìœ„í—˜ ì¹´í…Œê³ ë¦¬ì—ì„œ ë‚®ì€ ì ìˆ˜ë¥¼ ë°›ëŠ”ë‹¤. ë°˜ë©´ ëª…ì‹œì ìœ¼ë¡œ ìœ í•´í•œ ì½˜í…ì¸ ëŠ” í•´ë‹¹í•˜ëŠ” íŠ¹ì • ì¹´í…Œê³ ë¦¬ì—ì„œ ë†’ì€ ì ìˆ˜ë¥¼ ë°›ì•„ ìë™ìœ¼ë¡œ í”Œë˜ê·¸ëœë‹¤. ê°€ì¥ í¥ë¯¸ë¡œìš´ ë¶€ë¶„ì€ ê²½ê³„ì„  ì‚¬ë¡€ë“¤ë¡œ, ë§¥ë½ì— ë”°ë¼ ë‹¤ë¥´ê²Œ í•´ì„ë  ìˆ˜ ìˆëŠ” ë‚´ìš©ë“¤ì´ë‹¤.\n\n\n::: {.cell}\n\n```{.python .cell-code .code-overflow-wrap}\n# ì•ˆì „í•œ í…ìŠ¤íŠ¸ ì¤‘ì¬\nsafe_text = \"ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ë„¤ìš”. ë°ì´í„° ë¶„ì„ì— ëŒ€í•´ ë°°ìš°ê³  ì‹¶ìŠµë‹ˆë‹¤.\"\n\nresponse = client.moderations.create(\n    input=safe_text,\n    model=\"omni-moderation-latest\"\n)\n\nresult = response.results[0]\nprint(f\"ì…ë ¥ í…ìŠ¤íŠ¸: {safe_text}\")\nprint(f\"ìœ„í—˜ í”Œë˜ê·¸: {result.flagged}\")\n\n# Categories ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜\ncategories_dict = dict(result.categories)\nprint(f\"ëª¨ë“  ì¹´í…Œê³ ë¦¬ ì•ˆì „: {not any(categories_dict.values())}\")\n```\n:::\n\n\n```markdown\nì…ë ¥ í…ìŠ¤íŠ¸: ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ë„¤ìš”. ë°ì´í„° ë¶„ì„ì— ëŒ€í•´ ë°°ìš°ê³  ì‹¶ìŠµë‹ˆë‹¤.\nìœ„í—˜ í”Œë˜ê·¸: False\nëª¨ë“  ì¹´í…Œê³ ë¦¬ ì•ˆì „: True\n```\n\nì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œëŠ” ë‹¤ì–‘í•œ ìœ í˜•ì˜ ìœ í•´ ì½˜í…ì¸ ë¥¼ ë§Œë‚  ìˆ˜ ìˆìœ¼ë©°, ê°ê°ì€ ì„œë¡œ ë‹¤ë¥¸ ìœ„í—˜ ì¹´í…Œê³ ë¦¬ì—ì„œ ë†’ì€ ì ìˆ˜ë¥¼ ë°›ëŠ”ë‹¤. ì˜ˆë¥¼ ë“¤ì–´ í˜ì˜¤ í‘œí˜„ì€ `hate`ì™€ `harassment` ì¹´í…Œê³ ë¦¬ì—ì„œ, í­ë ¥ì  ë‚´ìš©ì€ `violence` ì¹´í…Œê³ ë¦¬ì—ì„œ, ìí•´ ê´€ë ¨ ë‚´ìš©ì€ `self-harm` ì¹´í…Œê³ ë¦¬ì—ì„œ ë†’ì€ ì ìˆ˜ë¥¼ ë°›ëŠ”ë‹¤. ìƒˆë¡­ê²Œ ì¶”ê°€ëœ `illicit` ì¹´í…Œê³ ë¦¬ëŠ” ë¶ˆë²• í–‰ìœ„ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì§€ì‹œì‚¬í•­ì„ íƒì§€í•˜ì—¬ ë²•ì  ë¬¸ì œë¥¼ ì‚¬ì „ì— ë°©ì§€í•œë‹¤.\n\n\n::: {.cell}\n\n```{.python .cell-code .code-overflow-wrap}\n# ìœ„í—˜í•œ í…ìŠ¤íŠ¸ë“¤ (êµìœ¡ ëª©ì )\ntest_texts = [\n    \"íŠ¹ì • ì§‘ë‹¨ì„ í–¥í•œ í˜ì˜¤ í‘œí˜„ì´ ë‹´ê¸´ í…ìŠ¤íŠ¸\",\n    \"í­ë ¥ì ì¸ ë‚´ìš©ì´ í¬í•¨ëœ ìœ„í˜‘ì  ë©”ì‹œì§€\",\n    \"ìí•´ë¥¼ ì¡°ì¥í•˜ëŠ” ë‚´ìš©\",\n    \"ë¶ˆë²•ì ì¸ í–‰ìœ„ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì§€ì‹œì‚¬í•­\"\n]\n\nfor i, text in enumerate(test_texts, 1):\n    print(f\"\\n=== í…ŒìŠ¤íŠ¸ {i} ===\")\n    \n    response = client.moderations.create(\n        input=text,\n        model=\"omni-moderation-latest\"\n    )\n    \n    result = response.results[0]\n    print(f\"í…ìŠ¤íŠ¸: {text}\")\n    print(f\"ìœ„í—˜ í”Œë˜ê·¸: {result.flagged}\")\n    \n    # ìœ„ë°˜ëœ ì¹´í…Œê³ ë¦¬ë§Œ í‘œì‹œ (Categories ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜)\n    categories_dict = dict(result.categories)\n    violated_categories = [cat for cat, violated in categories_dict.items() if violated]\n    if violated_categories:\n        print(f\"ìœ„ë°˜ ì¹´í…Œê³ ë¦¬: {', '.join(violated_categories)}\")\n    \n    # ë†’ì€ ì ìˆ˜ì˜ ì¹´í…Œê³ ë¦¬ í‘œì‹œ (CategoryScores ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜)\n    scores_dict = dict(result.category_scores)\n    high_scores = {cat: score for cat, score in scores_dict.items() if score > 0.1}\n    if high_scores:\n        print(\"ë†’ì€ ìœ„í—˜ë„ ì ìˆ˜:\")\n        for cat, score in sorted(high_scores.items(), key=lambda x: x[1], reverse=True):\n            print(f\"  {cat}: {score:.4f}\")\n```\n:::\n\n\n```markdown\n=== í…ŒìŠ¤íŠ¸ 1 ===\ní…ìŠ¤íŠ¸: íŠ¹ì • ì§‘ë‹¨ì„ í–¥í•œ í˜ì˜¤ í‘œí˜„ì´ ë‹´ê¸´ í…ìŠ¤íŠ¸\nìœ„í—˜ í”Œë˜ê·¸: False\në†’ì€ ìœ„í—˜ë„ ì ìˆ˜:\n  harassment: 0.1435\n\n=== í…ŒìŠ¤íŠ¸ 2 ===\ní…ìŠ¤íŠ¸: í­ë ¥ì ì¸ ë‚´ìš©ì´ í¬í•¨ëœ ìœ„í˜‘ì  ë©”ì‹œì§€\nìœ„í—˜ í”Œë˜ê·¸: True\nìœ„ë°˜ ì¹´í…Œê³ ë¦¬: violence\në†’ì€ ìœ„í—˜ë„ ì ìˆ˜:\n  violence: 0.3521\n\n=== í…ŒìŠ¤íŠ¸ 3 ===\ní…ìŠ¤íŠ¸: ìí•´ë¥¼ ì¡°ì¥í•˜ëŠ” ë‚´ìš©\nìœ„í—˜ í”Œë˜ê·¸: True\nìœ„ë°˜ ì¹´í…Œê³ ë¦¬: self_harm, self_harm_intent, self-harm/intent, self-harm\në†’ì€ ìœ„í—˜ë„ ì ìˆ˜:\n  self_harm: 0.4342\n  self_harm_intent: 0.2915\n  self_harm_instructions: 0.1795\n\n=== í…ŒìŠ¤íŠ¸ 4 ===\ní…ìŠ¤íŠ¸: ë¶ˆë²•ì ì¸ í–‰ìœ„ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì§€ì‹œì‚¬í•­\nìœ„í—˜ í”Œë˜ê·¸: True\nìœ„ë°˜ ì¹´í…Œê³ ë¦¬: illicit\në†’ì€ ìœ„í—˜ë„ ì ìˆ˜:\n  illicit: 0.4992\n```\n\níŠ¹íˆ ì£¼ëª©í•  ì ì€ ê²½ê³„ì„  ì‚¬ë¡€ë“¤ì´ë‹¤. ëª¨ë“  ì½˜í…ì¸ ê°€ ëª…í™•íˆ ì•ˆì „í•˜ê±°ë‚˜ ìœ„í—˜í•œ ê²ƒì€ ì•„ë‹ˆë©°, ë§¥ë½ì— ë”°ë¼ ë‹¤ë¥´ê²Œ í•´ì„ë  ìˆ˜ ìˆëŠ” ë‚´ìš©ë“¤ì€ ì¶”ê°€ì ì¸ ì¸ê°„ ê²€í† ë‚˜ ë” ì •êµí•œ ì •ì±… ì ìš©ì´ í•„ìš”í•˜ë‹¤. ì˜ˆë¥¼ ë“¤ì–´ \"ê²Œì„ì—ì„œ ì ì„ ë¬¼ë¦¬ì³¤ë‹¤\"ëŠ” í‘œí˜„ì€ ê²Œì„ ë§¥ë½ì—ì„œëŠ” ìì—°ìŠ¤ëŸ½ì§€ë§Œ ì¤‘ì¬ ì‹œìŠ¤í…œì—ì„œëŠ” í­ë ¥ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜ë  ìˆ˜ ìˆë‹¤. ì´ëŸ¬í•œ ê²½ìš° ê°œë°œìëŠ” ì„ê³„ê°’ ì¡°ì •ì´ë‚˜ ì¶”ê°€ì ì¸ ë§¥ë½ ë¶„ì„ì„ í†µí•´ ì •í™•ì„±ì„ ë†’ì¼ ìˆ˜ ìˆë‹¤.\n\n\n::: {.cell}\n\n```{.python .cell-code .code-overflow-wrap}\n# ê²½ê³„ì„  ì‚¬ë¡€ë“¤ - ì»¨í…ìŠ¤íŠ¸ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆëŠ” ë‚´ìš©\nborderline_texts = [\n    \"ê²Œì„ì—ì„œ ì ì„ ë¬¼ë¦¬ì³¤ë‹¤!\",  # ê²Œì„ í­ë ¥ vs ì‹¤ì œ í­ë ¥\n    \"ë‹¤ì´ì–´íŠ¸ë¥¼ ìœ„í•´ ì‹ì‚¬ë¥¼ ê±°ë¥´ê³  ìˆì–´ìš”\",  # ê±´ê°•í•œ ë‹¤ì´ì–´íŠ¸ vs ìí•´\n    \"ì´ ì •ì±…ì— ê°•ë ¥íˆ ë°˜ëŒ€í•©ë‹ˆë‹¤\",  # ì •ë‹¹í•œ ë¹„íŒ vs í˜ì˜¤\n    \"ìˆ ì„ ë§Œë“œëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”\"  # í•©ë²•ì  ì •ë³´ vs ë¶ˆë²• ì§€ì‹œ\n]\n\nprint(\"ê²½ê³„ì„  ì‚¬ë¡€ ë¶„ì„:\")\nfor text in borderline_texts:\n    response = client.moderations.create(\n        input=text,\n        model=\"omni-moderation-latest\"\n    )\n    \n    result = response.results[0]\n    print(f\"\\ní…ìŠ¤íŠ¸: '{text}'\")\n    print(f\"í”Œë˜ê·¸: {result.flagged}\")\n    \n    # 0.01 ì´ìƒì˜ ì ìˆ˜ë¥¼ ê°€ì§„ ì¹´í…Œê³ ë¦¬ í‘œì‹œ (CategoryScores ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜)\n    scores_dict = dict(result.category_scores)\n    notable_scores = {cat: score for cat, score in scores_dict.items() if score > 0.01}\n    if notable_scores:\n        print(\"ì£¼ëª©í• ë§Œí•œ ì ìˆ˜:\")\n        for cat, score in sorted(notable_scores.items(), key=lambda x: x[1], reverse=True):\n            print(f\"  {cat}: {score:.4f}\")\n    else:\n        print(\"ëª¨ë“  ì¹´í…Œê³ ë¦¬ì—ì„œ ë‚®ì€ ìœ„í—˜ë„\")\n```\n:::\n\n\n```markdown\nê²½ê³„ì„  ì‚¬ë¡€ ë¶„ì„:\n\ní…ìŠ¤íŠ¸: 'ê²Œì„ì—ì„œ ì ì„ ë¬¼ë¦¬ì³¤ë‹¤!'\ní”Œë˜ê·¸: True\nì£¼ëª©í• ë§Œí•œ ì ìˆ˜:\n  violence: 0.4290\n  illicit: 0.0201\n\ní…ìŠ¤íŠ¸: 'ë‹¤ì´ì–´íŠ¸ë¥¼ ìœ„í•´ ì‹ì‚¬ë¥¼ ê±°ë¥´ê³  ìˆì–´ìš”'\ní”Œë˜ê·¸: False\nì£¼ëª©í• ë§Œí•œ ì ìˆ˜:\n  self_harm: 0.0102\n\ní…ìŠ¤íŠ¸: 'ì´ ì •ì±…ì— ê°•ë ¥íˆ ë°˜ëŒ€í•©ë‹ˆë‹¤'\ní”Œë˜ê·¸: False\nëª¨ë“  ì¹´í…Œê³ ë¦¬ì—ì„œ ë‚®ì€ ìœ„í—˜ë„\n\ní…ìŠ¤íŠ¸: 'ìˆ ì„ ë§Œë“œëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”'\ní”Œë˜ê·¸: True\nì£¼ëª©í• ë§Œí•œ ì ìˆ˜:\n  illicit: 0.6243\n  illicit_violent: 0.1666\n```\n\n### ë©€í‹°ëª¨ë‹¬ ì¤‘ì¬ì™€ ì´ë¯¸ì§€ ì²˜ë¦¬\n\nì´ë¯¸ì§€ ì¤‘ì¬ëŠ” 2025ë…„ OpenAI ì¤‘ì¬ ì‹œìŠ¤í…œì˜ ê°€ì¥ í˜ì‹ ì ì¸ ê¸°ëŠ¥ ì¤‘ í•˜ë‚˜ë‹¤. ê¸°ì¡´ í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¤‘ì¬ì˜ í•œê³„ë¥¼ ë›°ì–´ë„˜ì–´ ì‹œê°ì  ì½˜í…ì¸ ê¹Œì§€ í¬ê´„í•˜ëŠ” ì¢…í•©ì ì¸ ì•ˆì „ ê´€ë¦¬ê°€ ê°€ëŠ¥í•´ì¡Œë‹¤. ì´ëŠ” ì†Œì…œ ë¯¸ë””ì–´, ì´ë¯¸ì§€ ê³µìœ  í”Œë«í¼, ì»¤ë®¤ë‹ˆí‹° ì‚¬ì´íŠ¸ ë“±ì—ì„œ í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œëŠ” í¬ì°©í•˜ê¸° ì–´ë ¤ìš´ ë‹¤ì–‘í•œ í˜•íƒœì˜ ìœ í•´ ì½˜í…ì¸ ë¥¼ ìë™ìœ¼ë¡œ íƒì§€í•  ìˆ˜ ìˆìŒì„ ì˜ë¯¸í•œë‹¤.\n\nì´ë¯¸ì§€ ì¤‘ì¬ì—ì„œëŠ” í­ë ¥(`violence`, `violence/graphic`), ìí•´(`self-harm` ê´€ë ¨), ì„±ì  ì½˜í…ì¸ (`sexual`) ì¹´í…Œê³ ë¦¬ë¥¼ ì§€ì›í•œë‹¤. í…ìŠ¤íŠ¸ ì¤‘ì¬ì™€ ë§ˆì°¬ê°€ì§€ë¡œ ê° ì¹´í…Œê³ ë¦¬ë³„ ì„¸ë°€í•œ ì ìˆ˜ë¥¼ ì œê³µí•˜ì—¬ í”Œë«í¼ì˜ ì •ì±…ì— ë§ëŠ” ì„ê³„ê°’ ì„¤ì •ì´ ê°€ëŠ¥í•˜ë‹¤. íŠ¹íˆ ê·¸ë˜í”½í•œ í­ë ¥ ì½˜í…ì¸ ì™€ ì¼ë°˜ì ì¸ í­ë ¥ ì½˜í…ì¸ ë¥¼ êµ¬ë¶„í•˜ì—¬ ë¶„ë¥˜í•˜ë¯€ë¡œ, ì—°ë ¹ ì œí•œì´ë‚˜ ê²½ê³  í‘œì‹œ ë“± ì°¨ë“±ì ì¸ ì •ì±… ì ìš©ì´ ê°€ëŠ¥í•˜ë‹¤. ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ë¶„ì„í•  ìˆ˜ ìˆì–´ ë§¥ë½ì„ ê³ ë ¤í•œ ë”ìš± ì •í™•í•œ ì¤‘ì¬ê°€ ê°€ëŠ¥í•˜ë©°, ì´ëŠ” ê¸°ì¡´ ì´ë¯¸ì§€ ë¶„ë¥˜ ì‹œìŠ¤í…œì˜ í•œê³„ë¥¼ í¬ê²Œ ê°œì„ í•œ ê²ƒì´ë‹¤.\n\n::: {.cell}\n\n```{.python .cell-code .code-overflow-wrap}\nimport base64\n\n# ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©\ndef encode_image(image_path):\n    with open(image_path, \"rb\") as image_file:\n        return base64.b64encode(image_file.read()).decode('utf-8')\n\n# ì´ë¯¸ì§€ ì¤‘ì¬\nimage_base64 = encode_image(\"images/gangnam_image.png\")\n\nresponse = client.moderations.create(\n    input=[\n        {\n            \"type\": \"image_url\",\n            \"image_url\": {\n                \"url\": f\"data:image/jpeg;base64,{image_base64}\"\n            }\n        }\n    ],\n    model=\"omni-moderation-latest\"\n)\n\n# ì´ë¯¸ì§€ ì¤‘ì¬ ê²°ê³¼ í™•ì¸\nresult = response.results[0]\nprint(f\"ì´ë¯¸ì§€ ìœ„í—˜ í”Œë˜ê·¸: {result.flagged}\")\n\n# ì´ë¯¸ì§€ì—ì„œ ì§€ì›ë˜ëŠ” ì¹´í…Œê³ ë¦¬: violence, self-harm, sexual\nsupported_categories = ['violence', 'violence/graphic', 'self-harm', 'self-harm/intent', \n                       'self-harm/instructions', 'sexual']\n\nfor category in supported_categories:\n    if category in result.category_scores:\n        score = result.category_scores[category]\n        if score > 0.01:\n            print(f\"ì´ë¯¸ì§€ {category}: {score:.4f}\")\n```\n:::\n\n\n```markdown\nì´ë¯¸ì§€ ìœ„í—˜ í”Œë˜ê·¸: False\n```\n\n## ë¹„ìš© ìµœì í™”\\index{ë¹„ìš© ìµœì í™”} íŒ\n\nAI API ì‚¬ìš© ë¹„ìš©ì€ í”„ë¡œì íŠ¸ì˜ ì§€ì†ê°€ëŠ¥ì„±ì— ì§ì ‘ì ì¸ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì¤‘ìš”í•œ ìš”ì†Œë‹¤. ì ì ˆí•œ ìµœì í™” ì „ëµì„ í†µí•´ ì„±ëŠ¥ ì €í•˜ ì—†ì´ ë¹„ìš©ì„ í¬ê²Œ ì ˆì•½í•  ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” íŠ¹íˆ ëŒ€ê·œëª¨ ì„œë¹„ìŠ¤ë‚˜ ì¥ê¸°ê°„ ìš´ì˜ë˜ëŠ” ì‹œìŠ¤í…œì—ì„œ ì¤‘ìš”í•˜ë‹¤. OpenAI API [@openai2025pricing]ì˜ ë¹„ìš©ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ë‹¤ì–‘í•œ ìµœì í™” ê¸°ë²•ì„ ì†Œê°œí•œë‹¤.\n\n### ì ì ˆí•œ ëª¨ë¸ ì„ íƒ\n\nëª¨ë¸ ì„ íƒì€ ë¹„ìš© ìµœì í™”ì˜ ì²« ë²ˆì§¸ì´ì ê°€ì¥ ì¤‘ìš”í•œ ë‹¨ê³„ë‹¤. ì‘ì—…ì˜ ë³µì¡ì„±ê³¼ ìš”êµ¬ë˜ëŠ” í’ˆì§ˆ ìˆ˜ì¤€ì„ ì •í™•íˆ íŒŒì•…í•˜ì—¬ ê³¼ë„í•œ ì„±ëŠ¥ì˜ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•´ì•¼ í•œë‹¤. ëª¨ë¸ë³„ ì„±ëŠ¥ê³¼ ë¹„ìš©ì„ ê³ ë ¤í•˜ì—¬ ì‘ì—…ì— ë§ëŠ” ëª¨ë¸ì„ ì„ íƒí•œë‹¤.\n\n\n::: {.cell}\n\n```{.python .cell-code .code-overflow-wrap}\n# 2025ë…„ ê¸°ì¤€ ëª¨ë¸ë³„ ê°€ê²© ë° ìš©ë„\nmodel_guide = {\n    \"gpt-4o\": {\n        \"input\": 0.0025,  # $/1K tokens\n        \"output\": 0.01,\n        \"ìš©ë„\": \"ìµœê³  ì„±ëŠ¥ì´ í•„ìš”í•œ ë³µì¡í•œ ì‘ì—…, ë©€í‹°ëª¨ë‹¬\",\n        \"ì˜ˆì‹œ\": \"ë³µì¡í•œ ë¶„ì„, ì½”ë“œ ìƒì„±, ì´ë¯¸ì§€ ì²˜ë¦¬\"\n    },\n    \"gpt-4o-mini\": {\n        \"input\": 0.00015,\n        \"output\": 0.0006,\n        \"ìš©ë„\": \"ì¼ë°˜ì ì¸ ì‘ì—…, ê°€ì„±ë¹„ ìµœê³ \",\n        \"ì˜ˆì‹œ\": \"í…ìŠ¤íŠ¸ ìš”ì•½, ë²ˆì—­, ì¼ë°˜ ì§ˆë‹µ\"\n    },\n    \"gpt-3.5-turbo\": {\n        \"input\": 0.0005,\n        \"output\": 0.0015,\n        \"ìš©ë„\": \"ê°„ë‹¨í•œ ì‘ì—…, ë¹ ë¥¸ ì‘ë‹µ\",\n        \"ì˜ˆì‹œ\": \"ì±—ë´‡, ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ìƒì„±\"\n    },\n    \"o1-mini\": {\n        \"input\": 0.003,\n        \"output\": 0.012,\n        \"ìš©ë„\": \"ë³µì¡í•œ ì¶”ë¡ , ìˆ˜í•™ ë¬¸ì œ\",\n        \"ì˜ˆì‹œ\": \"ë…¼ë¦¬ì  ì¶”ë¡ , ë³µì¡í•œ ê³„ì‚°\"\n    }\n}\n\ndef recommend_model(task_complexity, budget_priority=True):\n    \"\"\"ì‘ì—… ë³µì¡ë„ì™€ ì˜ˆì‚° ìš°ì„ ìˆœìœ„ì— ë”°ë¥¸ ëª¨ë¸ ì¶”ì²œ\"\"\"\n    if task_complexity == \"simple\" and budget_priority:\n        return \"gpt-4o-mini\"\n    elif task_complexity == \"simple\":\n        return \"gpt-3.5-turbo\"\n    elif task_complexity == \"complex\" and budget_priority:\n        return \"gpt-4o-mini\"\n    elif task_complexity == \"reasoning\":\n        return \"o1-mini\"\n    else:\n        return \"gpt-4o\"\n\n# ì‚¬ìš© ì˜ˆì‹œ\nprint(f\"ê°„ë‹¨í•œ ì‘ì—… (ì˜ˆì‚° ì¤‘ì‹œ): {recommend_model('simple', True)}\")\nprint(f\"ë³µì¡í•œ ì‘ì—… (ì„±ëŠ¥ ì¤‘ì‹œ): {recommend_model('complex', False)}\")\n```\n:::\n\n\n```markdown\nê°„ë‹¨í•œ ì‘ì—… (ì˜ˆì‚° ì¤‘ì‹œ): gpt-4o-mini\në³µì¡í•œ ì‘ì—… (ì„±ëŠ¥ ì¤‘ì‹œ): gpt-4o\n```\n\n### í† í° ì‚¬ìš©ëŸ‰ ìµœì í™”\n\ní† í°ì€ API ë¹„ìš© ê³„ì‚°ì˜ ê¸°ë³¸ ë‹¨ìœ„ì´ë¯€ë¡œ ì •í™•í•œ ê³„ì‚°ê³¼ ì˜ˆì¸¡ì´ í•„ìˆ˜ì ì´ë‹¤. ì˜ˆìƒì¹˜ ëª»í•œ ë¹„ìš© ì´ˆê³¼ë¥¼ ë°©ì§€í•˜ê³  í”„ë¡œì íŠ¸ ì˜ˆì‚°ì„ íš¨ê³¼ì ìœ¼ë¡œ ê´€ë¦¬í•  ìˆ˜ ìˆë‹¤. OpenAI Tokenizer [@openai2025tokenizer]ë¥¼ í™œìš©í•˜ì—¬ ì •í™•í•œ í† í° ìˆ˜ë¥¼ ê³„ì‚°í•˜ê³  ë¹„ìš©ì„ ì˜ˆì¸¡í•œë‹¤.\n\n\n::: {.cell}\n\n```{.python .cell-code .code-overflow-wrap}\nimport tiktoken\n\ndef count_tokens(text, model=\"gpt-4o-mini\"):\n    \"\"\"ì •í™•í•œ í† í° ìˆ˜ ê³„ì‚°\"\"\"\n    try:\n        encoding = tiktoken.encoding_for_model(model)\n    except KeyError:\n        encoding = tiktoken.get_encoding(\"cl100k_base\")  # ê¸°ë³¸ ì¸ì½”ë”©\n    return len(encoding.encode(text))\n\ndef estimate_cost(prompt, response=\"\", model=\"gpt-4o-mini\"):\n    \"\"\"API í˜¸ì¶œ ë¹„ìš© ì¶”ì •\"\"\"\n    model_pricing = {\n        \"gpt-4o-mini\": {\"input\": 0.00015, \"output\": 0.0006},\n        \"gpt-4o\": {\"input\": 0.0025, \"output\": 0.01},\n        \"gpt-3.5-turbo\": {\"input\": 0.0005, \"output\": 0.0015}\n    }\n    \n    input_tokens = count_tokens(prompt, model)\n    output_tokens = count_tokens(response, model) if response else 0\n    \n    pricing = model_pricing.get(model, model_pricing[\"gpt-4o-mini\"])\n    \n    input_cost = (input_tokens / 1000) * pricing[\"input\"]\n    output_cost = (output_tokens / 1000) * pricing[\"output\"]\n    total_cost = input_cost + output_cost\n    \n    return {\n        \"input_tokens\": input_tokens,\n        \"output_tokens\": output_tokens,\n        \"input_cost\": input_cost,\n        \"output_cost\": output_cost,\n        \"total_cost\": total_cost\n    }\n\n# í”„ë¡¬í”„íŠ¸ ìµœì í™” ì˜ˆì‹œ\nverbose_prompt = \"\"\"\nì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” ë°ì´í„° ë¶„ì„ì„ ê³µë¶€í•˜ê³  ìˆëŠ” í•™ìƒì…ë‹ˆë‹¤. \níŒŒì´ì¬ê³¼ R ì–¸ì–´ ì¤‘ì—ì„œ ì–´ë–¤ ê²ƒì´ ë” ì¢‹ì€ì§€ ë§¤ìš° ìì„¸í•˜ê³  \nêµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.\n\"\"\"\n\noptimized_prompt = \"íŒŒì´ì¬ vs R: ë°ì´í„° ë¶„ì„ìš© ì–¸ì–´ ë¹„êµ (ì¥ë‹¨ì , ì‚¬ìš© ì‚¬ë¡€)\"\n\nprint(\"=== í† í° ë° ë¹„ìš© ë¹„êµ ===\")\nverbose_cost = estimate_cost(verbose_prompt)\noptimized_cost = estimate_cost(optimized_prompt)\n\nprint(f\"ì¥í™©í•œ í”„ë¡¬í”„íŠ¸: {verbose_cost['input_tokens']} í† í°, ${verbose_cost['input_cost']:.6f}\")\nprint(f\"ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸: {optimized_cost['input_tokens']} í† í°, ${optimized_cost['input_cost']:.6f}\")\nprint(f\"ì ˆì•½: {verbose_cost['input_tokens'] - optimized_cost['input_tokens']} í† í°\")\n```\n:::\n\n\n```markdown\n=== í† í° ë° ë¹„ìš© ë¹„êµ ===\nì¥í™©í•œ í”„ë¡¬í”„íŠ¸: 45 í† í°, $0.000007\nìµœì í™”ëœ í”„ë¡¬í”„íŠ¸: 21 í† í°, $0.000003\nì ˆì•½: 24 í† í°\n```\n\n### í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§\n\níš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ëŠ” ë” ì ì€ í† í°ìœ¼ë¡œ ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ì–»ëŠ” í•µì‹¬ ë°©ë²•ì´ë‹¤. ëª…í™•í•˜ê³  êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ëŠ” AIê°€ ì˜ë„ë¥¼ ì •í™•íˆ íŒŒì•…í•˜ê²Œ í•˜ì—¬ ë¶ˆí•„ìš”í•œ ì¬ì‹œë„ë¥¼ ì¤„ì¸ë‹¤.\n\n\n::: {.cell}\n\n```{.python .cell-code .code-overflow-wrap}\n# ë¹„íš¨ìœ¨ì ì¸ í”„ë¡¬í”„íŠ¸\ninefficient_prompt = \"\"\"\në‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ì½ê³  ë§¤ìš° ìì„¸í•˜ê²Œ ë¶„ì„í•´ì£¼ì„¸ìš”. \nëª¨ë“  ì¸¡ë©´ì„ ê³ ë ¤í•˜ì—¬ ì™„ì „í•˜ê³  í¬ê´„ì ì¸ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.\nê°€ëŠ¥í•œ í•œ ë§ì€ ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n\ní…ìŠ¤íŠ¸: \"ë¨¸ì‹ ëŸ¬ë‹ì€ ì¸ê³µì§€ëŠ¥ì˜ í•œ ë¶„ì•¼ì…ë‹ˆë‹¤.\"\n\"\"\"\n\n# íš¨ìœ¨ì ì¸ í”„ë¡¬í”„íŠ¸\nefficient_prompt = \"\"\"\në‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ 3ì¤„ë¡œ ìš”ì•½í•˜ì„¸ìš”:\n\"ë¨¸ì‹ ëŸ¬ë‹ì€ ì¸ê³µì§€ëŠ¥ì˜ í•œ ë¶„ì•¼ì…ë‹ˆë‹¤.\"\n\ní˜•ì‹:\n1. ì •ì˜\n2. íŠ¹ì§•  \n3. ì‘ìš©ë¶„ì•¼\n\"\"\"\n\ndef create_structured_prompt(task, content, output_format=None, examples=None):\n    \"\"\"êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±\"\"\"\n    prompt_parts = [f\"ì‘ì—…: {task}\"]\n    \n    if content:\n        prompt_parts.append(f\"ë‚´ìš©: {content}\")\n    \n    if output_format:\n        prompt_parts.append(f\"ì¶œë ¥ í˜•ì‹: {output_format}\")\n    \n    if examples:\n        prompt_parts.append(f\"ì˜ˆì‹œ: {examples}\")\n    \n    return \"\\n\\n\".join(prompt_parts)\n\n# êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ\nstructured = create_structured_prompt(\n    task=\"í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„\",\n    content=\"ì´ ì˜í™” ì •ë§ ì¬ë¯¸ìˆì—ˆì–´ìš”!\",\n    output_format=\"JSON {sentiment: positive/negative/neutral, confidence: 0-1}\",\n    examples='{\"sentiment\": \"positive\", \"confidence\": 0.9}'\n)\n\nprint(\"=== êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ ===\")\nprint(structured)\n```\n:::\n\n\n```markdown\n=== êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ ===\nì‘ì—…: í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„\n\në‚´ìš©: ì´ ì˜í™” ì •ë§ ì¬ë¯¸ìˆì—ˆì–´ìš”!\n\nì¶œë ¥ í˜•ì‹: JSON {sentiment: positive/negative/neutral, confidence: 0-1}\n\nì˜ˆì‹œ: {\"sentiment\": \"positive\", \"confidence\": 0.9}\n```\n\n### ì‘ë‹µ ê¸¸ì´ ì œí•œ\n\nì¶œë ¥ í† í° ìˆ˜ë¥¼ ì œí•œí•˜ëŠ” ê²ƒì€ ì˜ˆì‚°ì„ ì—„ê²©íˆ ê´€ë¦¬í•˜ëŠ” íš¨ê³¼ì ì¸ ë°©ë²•ì´ë‹¤. íŠ¹íˆ ì‹¤ì‹œê°„ ì„œë¹„ìŠ¤ì—ì„œ ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë¹„ìš© êµ¬ì¡°ë¥¼ ë§Œë“¤ ë•Œ ìœ ìš©í•˜ë‹¤.\n\n\n::: {.cell}\n\n```{.python .cell-code .code-overflow-wrap}\n# max_tokensì„ í™œìš©í•œ ë¹„ìš© ì œì–´\ndef controlled_generation(prompt, max_budget_usd=0.01, model=\"gpt-4o-mini\"):\n    \"\"\"ì˜ˆì‚° ë‚´ì—ì„œ ì‘ë‹µ ìƒì„±\"\"\"\n    model_pricing = {\n        \"gpt-4o-mini\": {\"input\": 0.00015, \"output\": 0.0006},\n        \"gpt-4o\": {\"input\": 0.0025, \"output\": 0.01}\n    }\n    \n    input_tokens = count_tokens(prompt, model)\n    input_cost = (input_tokens / 1000) * model_pricing[model][\"input\"]\n    \n    # ë‚¨ì€ ì˜ˆì‚°ìœ¼ë¡œ ìƒì„± ê°€ëŠ¥í•œ ìµœëŒ€ í† í° ìˆ˜ ê³„ì‚°\n    remaining_budget = max_budget_usd - input_cost\n    max_output_tokens = int((remaining_budget / model_pricing[model][\"output\"]) * 1000)\n    \n    if max_output_tokens <= 0:\n        return {\"error\": \"ì…ë ¥ ë¹„ìš©ì´ ì˜ˆì‚°ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.\"}\n    \n    # ì‹¤ì œ API í˜¸ì¶œ (ì˜ˆì‹œ)\n    response = client.chat.completions.create(\n        model=model,\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n        max_tokens=min(max_output_tokens, 1000)  # ì•ˆì „ ì œí•œ\n    )\n    \n    return {\n        \"response\": response.choices[0].message.content,\n        \"input_tokens\": input_tokens,\n        \"estimated_output_tokens\": max_output_tokens,\n        \"estimated_cost\": max_budget_usd\n    }\n```\n:::\n\n\n### ìºì‹± ë° ì¬ì‚¬ìš©\n\në™ì¼í•˜ê±°ë‚˜ ìœ ì‚¬í•œ ìš”ì²­ì´ ë°˜ë³µë˜ëŠ” í™˜ê²½ì—ì„œëŠ” ìºì‹±ì„ í†µí•´ API í˜¸ì¶œ íšŸìˆ˜ë¥¼ í¬ê²Œ ì¤„ì¼ ìˆ˜ ìˆë‹¤. ì´ëŠ” ë¹„ìš© ì ˆì•½ë¿ë§Œ ì•„ë‹ˆë¼ ì‘ë‹µ ì†ë„ í–¥ìƒì—ë„ ê¸°ì—¬í•œë‹¤.\n\n\n::: {.cell}\n\n```{.python .cell-code .code-overflow-wrap}\nimport hashlib\nimport json\nfrom functools import lru_cache\n\nclass APICache:\n    \"\"\"API ì‘ë‹µ ìºì‹± í´ë˜ìŠ¤\"\"\"\n    \n    def __init__(self):\n        self.cache = {}\n    \n    def _generate_key(self, prompt, model, temperature=0):\n        \"\"\"ìºì‹œ í‚¤ ìƒì„±\"\"\"\n        cache_data = {\n            \"prompt\": prompt,\n            \"model\": model, \n            \"temperature\": temperature\n        }\n        return hashlib.md5(json.dumps(cache_data, sort_keys=True).encode()).hexdigest()\n    \n    def get_response(self, prompt, model=\"gpt-4o-mini\", temperature=0):\n        \"\"\"ìºì‹œëœ ì‘ë‹µ ì¡°íšŒ ë˜ëŠ” ìƒˆë¡œìš´ API í˜¸ì¶œ\"\"\"\n        cache_key = self._generate_key(prompt, model, temperature)\n        \n        if cache_key in self.cache:\n            print(\"ğŸ“‹ ìºì‹œì—ì„œ ì‘ë‹µ ë°˜í™˜\")\n            return self.cache[cache_key]\n        \n        print(\"ğŸŒ ìƒˆë¡œìš´ API í˜¸ì¶œ\")\n        response = client.chat.completions.create(\n            model=model,\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            temperature=temperature\n        )\n        \n        result = response.choices[0].message.content\n        self.cache[cache_key] = result\n        return result\n\n# ì‚¬ìš© ì˜ˆì‹œ\ncache = APICache()\n\n# ì²« ë²ˆì§¸ í˜¸ì¶œ - API ì‚¬ìš©\nresponse1 = cache.get_response(\"Pythonì˜ ì¥ì  3ê°€ì§€\")\n\n# ë‘ ë²ˆì§¸ ë™ì¼ í˜¸ì¶œ - ìºì‹œ ì‚¬ìš©\nresponse2 = cache.get_response(\"Pythonì˜ ì¥ì  3ê°€ì§€\")\n```\n:::\n\n\n\n```markdown\nğŸŒ ìƒˆë¡œìš´ API í˜¸ì¶œ\nğŸ“‹ ìºì‹œì—ì„œ ì‘ë‹µ ë°˜í™˜\n```\n\n### ë°°ì¹˜ ì²˜ë¦¬\n\nì—¬ëŸ¬ ê°œì˜ ê°œë³„ ìš”ì²­ ëŒ€ì‹  í•˜ë‚˜ì˜ ë°°ì¹˜ ìš”ì²­ìœ¼ë¡œ ì²˜ë¦¬í•˜ë©´ ì´ í† í° ìˆ˜ë¥¼ ì¤„ì´ê³  API í˜¸ì¶œ ì˜¤ë²„í—¤ë“œë¥¼ ìµœì†Œí™”í•  ìˆ˜ ìˆë‹¤. íŠ¹íˆ ëŒ€ëŸ‰ì˜ í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•  ë•Œ íš¨ê³¼ì ì´ë‹¤.\n\n\n::: {.cell}\n\n```{.python .cell-code .code-overflow-wrap}\ndef batch_process_texts(texts, instruction, model=\"gpt-4o-mini\"):\n    \"\"\"ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•˜ì—¬ ë¹„ìš© ì ˆì•½\"\"\"\n    \n    # ê°œë³„ ì²˜ë¦¬ vs ë°°ì¹˜ ì²˜ë¦¬ ë¹„êµ\n    individual_cost = 0\n    for text in texts:\n        prompt = f\"{instruction}\\n\\ní…ìŠ¤íŠ¸: {text}\"\n        cost = estimate_cost(prompt, model=model)\n        individual_cost += cost['total_cost']\n    \n    # ë°°ì¹˜ ì²˜ë¦¬\n    batch_prompt = f\"{instruction}\\n\\n\"\n    for i, text in enumerate(texts, 1):\n        batch_prompt += f\"{i}. {text}\\n\"\n    \n    batch_cost = estimate_cost(batch_prompt, model=model)\n    \n    print(f\"ê°œë³„ ì²˜ë¦¬ ì˜ˆìƒ ë¹„ìš©: ${individual_cost:.6f}\")\n    print(f\"ë°°ì¹˜ ì²˜ë¦¬ ì˜ˆìƒ ë¹„ìš©: ${batch_cost['total_cost']:.6f}\")\n    print(f\"ì ˆì•½ë¥ : {((individual_cost - batch_cost['total_cost']) / individual_cost) * 100:.1f}%\")\n    \n    # ì‹¤ì œ ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰\n    response = client.chat.completions.create(\n        model=model,\n        messages=[{\"role\": \"user\", \"content\": batch_prompt}]\n    )\n    \n    return response.choices[0].message.content\n\n# ì‚¬ìš© ì˜ˆì‹œ\ntexts_to_analyze = [\n    \"ì´ ì œí’ˆì€ ì •ë§ í›Œë¥­í•©ë‹ˆë‹¤!\",\n    \"ë°°ì†¡ì´ ë„ˆë¬´ ëŠ¦ì—ˆì–´ìš”.\",\n    \"ê°€ê²© ëŒ€ë¹„ ê´œì°®ì€ ê²ƒ ê°™ì•„ìš”.\",\n    \"ê³ ê° ì„œë¹„ìŠ¤ê°€ ë³„ë¡œì˜€ìŠµë‹ˆë‹¤.\"\n]\n\nbatch_result = batch_process_texts(\n    texts_to_analyze, \n    \"ë‹¤ìŒ í…ìŠ¤íŠ¸ë“¤ì˜ ê°ì •ì„ positive/negative/neutralë¡œ ë¶„ë¥˜í•˜ì„¸ìš”:\"\n)\n```\n:::\n\n\n\n```markdown\nê°œë³„ ì²˜ë¦¬ ì˜ˆìƒ ë¹„ìš©: $0.000018\në°°ì¹˜ ì²˜ë¦¬ ì˜ˆìƒ ë¹„ìš©: $0.000009\nì ˆì•½ë¥ : 48.7%\n```\n\n### ìŠ¤íŠ¸ë¦¬ë° ì¡°ê¸° ì¢…ë£Œ\n\nìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì—ì„œ í•„ìš”í•œ ì •ë³´ë¥¼ ì–»ëŠ” ì¦‰ì‹œ ì—°ê²°ì„ ì¢…ë£Œí•˜ë©´ ë¶ˆí•„ìš”í•œ í† í° ìƒì„±ì„ ë°©ì§€í•  ìˆ˜ ìˆë‹¤. ìš”ì•½ì´ë‚˜ í•µì‹¬ ì •ë³´ ì¶”ì¶œ ì‘ì—…ì—ì„œ íŠ¹íˆ ìœ ìš©í•˜ë‹¤.\n\n\n::: {.cell}\n\n```{.python .cell-code .code-overflow-wrap}\ndef streaming_with_early_stop(prompt, stop_conditions=None, model=\"gpt-4o-mini\"):\n    \"\"\"ìŠ¤íŠ¸ë¦¬ë°ì„ í™œìš©í•œ ì¡°ê¸° ì¢…ë£Œë¡œ ë¹„ìš© ì ˆì•½\"\"\"\n    \n    if stop_conditions is None:\n        stop_conditions = [\"ê²°ë¡ ì ìœ¼ë¡œ\", \"ìš”ì•½í•˜ë©´\", \"ë§ˆì§€ë§‰ìœ¼ë¡œ\"]\n    \n    response_text = \"\"\n    \n    stream = client.chat.completions.create(\n        model=model,\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n        stream=True,\n        max_tokens=500\n    )\n    \n    for chunk in stream:\n        if chunk.choices[0].delta.content:\n            content = chunk.choices[0].delta.content\n            response_text += content\n            print(content, end=\"\")\n            \n            # ì¡°ê¸° ì¢…ë£Œ ì¡°ê±´ í™•ì¸\n            for condition in stop_conditions:\n                if condition in response_text:\n                    print(f\"\\n\\n[ì¡°ê¸° ì¢…ë£Œ: '{condition}' ê°ì§€]\")\n                    return response_text\n    \n    return response_text\n\n# ì‚¬ìš© ì˜ˆì‹œ\nprompt = \"ë¨¸ì‹ ëŸ¬ë‹ì˜ ì¢…ë¥˜ì™€ íŠ¹ì§•ì— ëŒ€í•´ ê°„ëµíˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"\nresult = streaming_with_early_stop(prompt)\n```\n:::\n\n\n### ë¹„ìš© ëª¨ë‹ˆí„°ë§\n\nì‹¤ì‹œê°„ ë¹„ìš© ì¶”ì ì€ ì˜ˆì‚° ì´ˆê³¼ë¥¼ ë°©ì§€í•˜ê³  ì‚¬ìš© íŒ¨í„´ì„ ë¶„ì„í•˜ëŠ” ë° í•„ìˆ˜ì ì´ë‹¤. ì²´ê³„ì ì¸ ëª¨ë‹ˆí„°ë§ì„ í†µí•´ ìµœì í™” í¬ì¸íŠ¸ë¥¼ ì°¾ì•„ë‚¼ ìˆ˜ ìˆë‹¤.\n\n\n::: {.cell}\n\n```{.python .cell-code .code-overflow-wrap}\nclass CostMonitor:\n    \"\"\"API ì‚¬ìš©ëŸ‰ ë° ë¹„ìš© ëª¨ë‹ˆí„°ë§\"\"\"\n    \n    def __init__(self, daily_budget=1.0):\n        self.daily_budget = daily_budget\n        self.daily_usage = 0.0\n        self.call_history = []\n    \n    def track_call(self, model, input_tokens, output_tokens):\n        \"\"\"API í˜¸ì¶œ ì¶”ì \"\"\"\n        model_pricing = {\n            \"gpt-4o-mini\": {\"input\": 0.00015, \"output\": 0.0006},\n            \"gpt-4o\": {\"input\": 0.0025, \"output\": 0.01}\n        }\n        \n        pricing = model_pricing.get(model, model_pricing[\"gpt-4o-mini\"])\n        cost = (input_tokens/1000 * pricing[\"input\"]) + (output_tokens/1000 * pricing[\"output\"])\n        \n        self.daily_usage += cost\n        self.call_history.append({\n            \"model\": model,\n            \"input_tokens\": input_tokens,\n            \"output_tokens\": output_tokens,\n            \"cost\": cost,\n            \"cumulative\": self.daily_usage\n        })\n        \n        return self.check_budget()\n    \n    def check_budget(self):\n        \"\"\"ì˜ˆì‚° í™•ì¸\"\"\"\n        remaining = self.daily_budget - self.daily_usage\n        percentage = (self.daily_usage / self.daily_budget) * 100\n        \n        status = {\n            \"current_usage\": self.daily_usage,\n            \"daily_budget\": self.daily_budget,\n            \"remaining\": remaining,\n            \"percentage\": percentage,\n            \"warning\": percentage > 80,\n            \"exceeded\": remaining < 0\n        }\n        \n        if status[\"warning\"]:\n            print(f\"âš ï¸ ì˜ˆì‚°ì˜ {percentage:.1f}% ì‚¬ìš©ë¨\")\n        \n        if status[\"exceeded\"]:\n            print(f\"ğŸš« ì¼ì¼ ì˜ˆì‚° ì´ˆê³¼! (${self.daily_usage:.4f}/${self.daily_budget})\")\n        \n        return status\n\n# ì‚¬ìš© ì˜ˆì‹œ\nmonitor = CostMonitor(daily_budget=5.0)\n\n# API í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜\nstatus = monitor.track_call(\"gpt-4o-mini\", 100, 200)\nprint(f\"í˜„ì¬ ì‚¬ìš©ëŸ‰: ${status['current_usage']:.4f}\")\nprint(f\"ë‚¨ì€ ì˜ˆì‚°: ${status['remaining']:.4f}\")\n```\n:::\n\n\n```markdown\ní˜„ì¬ ì‚¬ìš©ëŸ‰: $0.0001\në‚¨ì€ ì˜ˆì‚°: $4.9999\n```\n\n### ì„±ëŠ¥ ëŒ€ ë¹„ìš© ë²¤ì¹˜ë§ˆí¬\n\nì •ê¸°ì ì¸ ë²¤ì¹˜ë§ˆí‚¹ì„ í†µí•´ ê° ëª¨ë¸ì˜ ê°€ì„±ë¹„ë¥¼ í‰ê°€í•˜ê³ , ìš”êµ¬ì‚¬í•­ ë³€í™”ì— ë”°ë¼ ëª¨ë¸ ì„ íƒì„ ì¡°ì •í•  ìˆ˜ ìˆë‹¤. ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì •ìœ¼ë¡œ ìµœì ì˜ ëª¨ë¸ ì¡°í•©ì„ ì°¾ëŠ”ë‹¤.\n\n\n::: {.cell}\n\n```{.python .cell-code .code-overflow-wrap}\ndef benchmark_models(test_prompts, models=None):\n    \"\"\"ëª¨ë¸ë³„ ì„±ëŠ¥ ëŒ€ë¹„ ë¹„ìš© ë¶„ì„\"\"\"\n    \n    if models is None:\n        models = [\"gpt-4o-mini\", \"gpt-3.5-turbo\", \"gpt-4o\"]\n    \n    results = []\n    \n    for model in models:\n        total_cost = 0\n        total_quality = 0\n        \n        for prompt in test_prompts:\n            cost_estimate = estimate_cost(prompt, model=model)\n            \n            # ì‹¤ì œë¡œëŠ” ì‘ë‹µ í’ˆì§ˆì„ í‰ê°€í•˜ëŠ” ë¡œì§ì´ í•„ìš”\n            # ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œë¡œ ê°„ë‹¨í•œ ì ìˆ˜ ì‚¬ìš©\n            quality_score = {\n                \"gpt-4o\": 9.5,\n                \"gpt-4o-mini\": 8.5, \n                \"gpt-3.5-turbo\": 7.5\n            }.get(model, 7.0)\n            \n            total_cost += cost_estimate['input_cost']\n            total_quality += quality_score\n        \n        avg_cost = total_cost / len(test_prompts)\n        avg_quality = total_quality / len(test_prompts)\n        value_score = avg_quality / (avg_cost * 1000)  # ê°€ì„±ë¹„ ì ìˆ˜\n        \n        results.append({\n            \"model\": model,\n            \"avg_cost_per_prompt\": avg_cost,\n            \"avg_quality\": avg_quality,\n            \"value_score\": value_score\n        })\n    \n    # ê²°ê³¼ ì •ë ¬ (ê°€ì„±ë¹„ ìˆœ)\n    results.sort(key=lambda x: x['value_score'], reverse=True)\n    \n    print(\"=== ëª¨ë¸ ì„±ëŠ¥ ëŒ€ë¹„ ë¹„ìš© ë¶„ì„ ===\")\n    for result in results:\n        print(f\"{result['model']}: í’ˆì§ˆ {result['avg_quality']:.1f}, \"\n              f\"ë¹„ìš© ${result['avg_cost_per_prompt']:.6f}, \"\n              f\"ê°€ì„±ë¹„ {result['value_score']:.1f}\")\n    \n    return results\n\n# í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸\ntest_prompts = [\n    \"Python ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜ ì„¤ëª…\",\n    \"ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì˜ ì°¨ì´ì \", \n    \"API ì„¤ê³„ ì›ì¹™ 3ê°€ì§€\"\n]\n\nbenchmark_results = benchmark_models(test_prompts)\n```\n:::\n\n\n```markdown\n=== ëª¨ë¸ ì„±ëŠ¥ ëŒ€ë¹„ ë¹„ìš© ë¶„ì„ ===\ngpt-4o-mini: í’ˆì§ˆ 8.5, ë¹„ìš© $0.000001, ê°€ì„±ë¹„ 5666.7\ngpt-3.5-turbo: í’ˆì§ˆ 7.5, ë¹„ìš© $0.000007, ê°€ì„±ë¹„ 1022.7\ngpt-4o: í’ˆì§ˆ 9.5, ë¹„ìš© $0.000025, ê°€ì„±ë¹„ 380.0\n```\n\nì´ëŸ¬í•œ ë¹„ìš© ìµœì í™” ê¸°ë²•ë“¤ì„ ì²´ê³„ì ìœ¼ë¡œ ì¡°í•©í•˜ì—¬ ì‚¬ìš©í•˜ë©´ ì„±ëŠ¥ ì €í•˜ ì—†ì´ OpenAI API ë¹„ìš©ì„ í¬ê²Œ ì ˆì•½í•  ìˆ˜ ìˆìœ¼ë©°, ì§€ì†ê°€ëŠ¥í•œ AI ì„œë¹„ìŠ¤ ê°œë°œì´ ê°€ëŠ¥í•˜ë‹¤.\n\n\n",
    "supporting": [
      "coding_openai_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}