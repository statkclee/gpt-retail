# 데이터 과학 방법론 {#sec-data-method}

1부와 2부에서 다룬 AI 범용기술 이론과 데이터 과학 기초는 이제 실전 적용을 위한 준비를 마쳤다. 이 장에서는 3부에서 다룰 4가지 사례 분석에 공통으로 적용되는 방법론 프레임워크를 제시한다. 이론과 실전을 연결하는 다리 역할을 하며, 재사용 가능한 분석 패턴을 명확히 한다.

![AI 데이터 과학 방법론 - 이론에서 실전으로](images/ai-data-science-method-framework.svg){#fig-ai-method-framework}

## 순환적 개선 프로세스

@fig-ai-method-framework 는 1-2부의 이론적 기초가 3부 실전 사례로 연결되는 전체 구조를 보여준다. 데이터 과학은 선형적 프로세스가 아니라 순환적 개선 과정이다. **문제 정의**에서는 비즈니스 질문을 측정 가능한 형태로 구체화한다. "왜 매출 격차가 6배인가?"나 "왜 쇼핑앱 체류시간이 3배 차이 나는가?"처럼 명확한 질문으로 시작해야 데이터 분석 방향이 잡힌다. **데이터 탐색**에서는 탐색적 분석과 시각화를 통해 패턴을 발견하고 초기 가설을 수립한다. R과 Python을 통합한 IDE 환경에서 데이터 품질을 확인하고 이상치를 처리하며 변수 간 관계를 파악한다. **인사이트 도출**은 통계 분석과 AI 보조 해석을 통해 데이터에 비즈니스 의미를 부여한다. "수치가 다르다"를 넘어 "왜 다른가"를 설명하며, "대형마트는 물량 전략, 체인슈퍼는 마진 전략"처럼 원인과 메커니즘을 밝혀낸다. **액션 설계**에서는 인사이트를 구체적 권장사항과 실행 계획으로 변환하고, gt 테이블과 ggplot2 그래프로 의사결정자가 즉시 이해할 수 있는 형태로 문서화한다.

4단계는 화살표로 연결되어 순차적으로 진행되지만, 각 단계에서 문제가 발견되면 이전 단계로 돌아가는 피드백 루프가 작동한다. 실패는 프로세스의 일부이며, 반복을 통해 분석 품질이 향상된다. 쇼핑앱 전쟁, 유통채널 전략, 급식비 절약, 농산물 정보 격차는 이 프레임워크를 각기 다른 비즈니스 맥락에 적용한 구체적 예시다.

## 실전 적용과 도구

4가지 사례는 서로 다른 비즈니스 질문을 다루지만 공통된 방법론과 도구를 공유한다. **쇼핑앱 전쟁**은 행동 차원 중심 분석으로 검색형(쿠팡 55초)과 발견형(에이블리 180초) 쇼핑 패러다임 본질적 차이를 규명한다. 2025년 1월 전국 데이터를 성별·연령대별로 세분화하여 앱별 전략 차별화를 입증한다. **유통채널 전략**은 성과 차원 중심 분석으로 대형마트와 체인슈퍼 간 매출 6배 격차 원인을 밝힌다. 52주 트렌드를 추적하여 물량 중심 vs 마진 중심 전략의 근본적 차이를 확인한다. **급식비 절약**은 효율성 차원 중심 분석으로 학교급식 식재료 조달의 채널별·지역별 가격 격차를 규명하며, 동일 품목에서도 조달 전략에 따라 상당한 예산 절감 가능성을 보여준다. **농산물 정보 격차**는 정보 소비 행태를 통해 디지털 계급사회 구조를 탐구하며, 체류시간과 직업군 기반으로 정보 엘리트층·실용 정보층·이슈 추종층의 3계층 분화를 밝혀낸다.

2부에서 다룬 도구들은 4가지 사례에 일관되게 적용된다. IDE 환경에서는 R(tidyverse, ggplot2, gt)과 Python(pandas, matplotlib)을 Quarto 문서 내에서 통합 실행하며, 코드 청크는 YAML 스타일(`#|`)로 작성한다. 계산 결과는 freeze 시스템으로 캐싱되어 재현성을 보장한다. 시각화는 gt 패키지로 데이터 테이블을 생성하고 컬럼 너비를 `pct()` 함수로 지정하며, ggplot2 그래프는 Apple Gothic 폰트를 적용해 고해상도로 출력한다. 모든 시각화는 브랜드 색상 팔레트(\_brand.yml)를 준수한다. 각 사례는 문제 정의로 시작해 데이터 탐색, 인사이트 도출, 액션 설계 순으로 전개되며, SVG 다이어그램은 개념 프레임워크를, R/Python 출력물은 실증 근거를 제공한다.

프레임워크가 중요한 이유는 세 가지다. 첫째, **재사용성**이다. 동일한 4단계 프로세스를 새로운 비즈니스 질문에 즉시 적용할 수 있다. 둘째, **협업 효율성**이다. 팀원 간 공통 언어와 작업 흐름을 공유하여 커뮤니케이션 비용을 줄인다. 셋째, **품질 일관성**이다. 표준화된 절차는 분석 품질을 보장하고 검증 가능성을 높인다.

## AI 협업 분석 프로세스

![AI 협업 기반 데이터 분석 워크플로우](images/ai-assisted-analysis-workflow.svg){#fig-ai-workflow}

@fig-ai-workflow 는 이 책의 4가지 사례 분석이 실제로 만들어진 과정을 보여준다. 각 데이터셋에 하루 동안 집중하며, Positron IDE 환경에서 Claude Code와의 대화형 분석을 통해 수십 번의 반복 끝에 최종 Quarto 문서를 완성했다. OpenAI Codex는 코드 자동완성과 리팩토링에서 보조 역할을 수행했다.

AI와 사람의 역할 분담이 명확했다. Claude Code는 데이터 탐색 코드 생성, 시각화 작성, 통계 분석 실행, 인사이트 해석, 서술형 문단 작성 등 분석의 약 60%를 담당했다. OpenAI Codex는 코드 자동완성과 구문 오류 수정으로 작업 속도를 높였다. 사람은 질문 설계, 결과 해석, 피드백 제공, 최종 큐레이션의 100%를 책임졌다. "체류시간 분포를 보여줘", "이 패턴을 문단으로 써줘", "그래프 색상을 브랜드 컬러로 바꿔줘" 같은 구체적 요청을 통해 AI를 지휘하며, 하루에 수십에서 수백 번의 대화를 반복했다. 이 과정에서 예상치 못한 패턴이 발견되고, 분석 방향이 실시간으로 조정되며, 점진적으로 품질이 개선되었다.

이 방법은 탐색적 자유도와 깊이 있는 인사이트 발견에서 강점을 보였지만, 재현성과 일관성에서는 과제를 남겼다. 대화 히스토리가 코드에 남지 않아 다른 사람이 동일한 과정을 재현하기 어렵고, 4개 파일 간 스타일과 구조가 미묘하게 달랐다. 향후 개선 방향으로는 대화 로그를 마크다운으로 기록하고, 공통 분석 패턴을 템플릿화하며, 핵심 함수를 `_common.R`에 모듈화하는 것이 유효하다. 그러나 이번 프로젝트에서는 탐색적 발견이 우선이었고, 책 집필이라는 목표에는 현재 방식이 적합했다. 다음 4개 장에서 이 방법론이 실제 유통 데이터에서 어떻게 작동하는지 확인할 것이다. 이론은 실전에서 검증되며, 실전은 이론으로 정제된다.
