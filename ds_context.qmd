# 컨텍스트 엔지니어링 {#sec-context-engineering}

**컨텍스트 엔지니어링\index{컨텍스트 엔지니어링}(Context Engineering)**은 대규모 언어 모델\index{대규모 언어 모델}(LLM\index{LLM})의 잠재력을 극대화하는 핵심 기술이다[@mei2025surveycontextengineeringlarge]. 이는 AI 에이전트\index{AI 에이전트}가 작업을 수행할 때 필요한 정보를 효과적으로 관리하고 활용하는 예술이자 과학으로, 에이전트의 "컨텍스트 창\index{컨텍스트 창}(context window)"을 적절한 정보로 채우는 체계적인 접근법이다[@langchain2024context].

## 컨텍스트 엔지니어링이란? {#sec-what-is-context-engineering}

컨텍스트 엔지니어링은 대규모 언어 모델(LLM)의 출력 품질을 극대화하기 위해 이상적인 컨텍스트 생성 함수 집합(F)을 찾는 최적화 문제다. 이는 단순히 프롬프트\index{프롬프트}를 작성하는 것을 넘어, 동적이고 구조화된 정보 구성 요소들의 복합체를 설계하는 과정이다.

### 핵심 구성 요소 {#sec-core-components}

컨텍스트(C)는 동적으로 구조화된 정보 구성 요소들의 집합으로 재개념화된다.

$$C = A(c_1, c_2, ..., c_n)$$

여기서 A는 고수준 어셈블리 함수이며, 각 구성 요소는 다음과 같다.

- **$c_{instr}$ (시스템 지침 및 규칙)**: 모델의 행동을 지시하고 제약하는 기본 명령어
- **$c_{know}$ (외부 지식)**: RAG와 같은 메커니즘을 통해 동적으로 검색되는 외부 정보
- **$c_{tools}$ (사용 가능한 외부 도구)**: LLM이 외부 환경과 상호작용하기 위한 도구 정의
- **$c_{mem}$ (영구 정보)**: 이전 상호 작용에서 얻은 영구적인 정보
- **$c_{state}$ (동적 상태)**: 사용자, 외부 세계, 또는 다중 에이전트 시스템의 현재 상태
- **$c_{query}$ (사용자의 즉각적인 요청)**: 사용자의 직접적인 질문이나 명령

::: {.callout-note}
## 프롬프트 엔지니어링과의 차이점
컨텍스트 엔지니어링은 프롬프트를 단순한 정적 문자열이 아닌, 동적이고 구조화된 정보 구성 요소들의 복합체로 인식한다는 점에서 전통적인 프롬프트 엔지니어링과 차별화된다[@mei2025surveycontextengineeringlarge].
:::

## 핵심 전략 4가지 {#sec-four-strategies}

효과적인 컨텍스트 엔지니어링은 네 가지 핵심 전략을 통해 구현된다[@langchain2024context].

![컨텍스트 엔지니어링 4가지 전략](images/context_engineering.png){#fig-context-enginnering-langchain}

### 컨텍스트 선택\index{선택} {#sec-select-context}

컨텍스트 선택(Compress Select)은 방대한 정보의 바다에서 현재 작업에 가장 관련성 높은 정보만을 추출하는 전략으로, 효과적인 컨텍스트 엔지니어링의 첫 번째 관문이다. 마치 숙련된 사서가 수만 권의 책 중에서 독자에게 꼭 필요한 자료만을 골라내는 것처럼, AI 시스템은 수많은 정보 중에서 현재 맥락에 가장 적합한 지식을 선별해야 한다.

이러한 선택 과정의 효과성을 극대화하기 위해 CLEAR 프레임워크\index{CLEAR 프레임워크}가 개발되었다. **간결성\index{간결성}(Conciseness)**은 불필요한 정보를 제거하고 핵심만을 추출하는 원칙으로, 제한된 컨텍스트 창을 최대한 효율적으로 활용할 수 있게 한다. **논리성\index{논리성}(Logicality)**은 정보 간의 논리적 연관성을 기반으로 선택하여, 일관성 있고 체계적인 컨텍스트를 구성한다. **명시성\index{명시성}(Explicitness)**은 선택 기준을 명확히 하여 재현 가능하고 예측 가능한 결과를 보장한다. **적응성\index{적응성}(Adaptability)**은 상황 변화에 따라 선택 전략을 동적으로 조정할 수 있는 유연성을 제공하며, **반사성\index{반사성}(Reflectiveness)**은 선택 결과를 지속적으로 평가하고 개선하는 피드백 메커니즘을 구현한다.

검색 증강 생성\index{검색 증강 생성}(RAG\index{RAG})은 이러한 선택 전략의 가장 대표적인 구현 사례다. RAG는 모델의 매개변수에 내재된 지식과 외부 데이터베이스에서 동적으로 검색한 정보를 유기적으로 결합하여, 최신성과 정확성을 동시에 확보한다. 이는 단순한 키워드 매칭을 넘어 의미적 유사도, 시간적 관련성, 정보의 신뢰도 등 다차원적 기준을 통해 최적의 정보를 선별한다:

```python
class RAGSystem:
    def __init__(self, retriever, generator):
        self.retriever = retriever
        self.generator = generator
    
    def select_context(self, query):
        # 의미적 유사도 기반 선택
        relevant_docs = self.retriever.search(query)
        
        # 시간적 관련성 고려
        recent_docs = self.filter_by_recency(relevant_docs)
        
        # 중요도 기반 우선순위화
        prioritized = self.prioritize_by_importance(recent_docs)
        
        return prioritized
```

::: {.callout-important}
## 선택의 중요성
모든 정보를 컨텍스트에 포함시키는 것은 오히려 성능을 저하시킬 수 있다. "적절한" 정보만을 선택하는 것이 핵심이다.
:::

### 컨텍스트 압축\index{압축} {#sec-compress-context}

컨텍스트 압축(Compress Context)은 정보의 본질은 보존하면서 표현의 효율성을 극대화하는 예술이다. 이는 마치 고해상도 이미지를 손실 없이 압축하는 것처럼, 핵심 정보는 그대로 유지하면서 토큰 사용량을 획기적으로 줄이는 전략이다. 특히 현대의 LLM들이 점점 더 긴 컨텍스트를 처리할 수 있게 되었지만, 이에 따른 계산 비용의 기하급수적 증가는 효율적인 압축 기법의 중요성을 더욱 부각시킨다.

압축 기법은 크게 세 가지 접근법으로 구분된다. 첫째, **요약 기반 압축**은 긴 문서나 대화를 핵심 내용만으로 축약하는 방법으로, 중복되거나 부차적인 정보를 제거하고 본질적인 메시지만을 추출한다. 이는 단순한 길이 축소가 아닌, 의미의 농축 과정이다. 둘째, **구조적 압축**은 정보를 보다 효율적인 형식으로 재구성하는 접근법이다. 예를 들어, 반복적인 패턴을 템플릿화하거나, 계층적 정보를 평면화하여 표현의 간결성을 높인다. 셋째, **선택적 압축**은 정보의 중요도에 따라 차등적으로 압축 수준을 조절하는 고급 기법이다. 핵심 정보는 상세히 보존하고, 보조적 정보는 높은 수준으로 압축하여 전체적인 균형을 맞춘다.

```python
class ContextCompressor:
    def compress(self, context, max_tokens):
        # 중요도 점수 계산
        importance_scores = self.calculate_importance(context)
        
        # 토큰 제한 내에서 최적화
        compressed = self.optimize_for_token_limit(
            context, importance_scores, max_tokens
        )
        
        return compressed
```

::: {.callout-warning}
## 계산 복잡도 문제
Mistral-7B 모델의 입력을 4K에서 128K 토큰으로 늘리면 계산량이 122배 증가한다. 효과적인 압축은 이러한 문제를 완화할 수 있다.
:::

### 컨텍스트 쓰기\index{쓰기} {#sec-write-context}

컨텍스트 쓰기(Write Context)는 AI 에이전트가 인간의 기억 시스템을 모방하여 정보를 체계적으로 저장하고 관리하는 전략이다. 이는 단순히 정보를 보관하는 것을 넘어, 미래의 작업에서 효과적으로 활용할 수 있도록 구조화하고 색인화하는 복잡한 과정이다. 제한된 컨텍스트 창이라는 AI의 근본적 한계를 극복하기 위해, 작업 중에 생성되거나 발견된 중요한 정보를 외부 메모리 시스템에 체계적으로 기록한다.


```{r}
#| label: tbl-memory-types
#| tbl-cap: "인간과 AI 에이전트의 메모리 유형 비교"
#| echo: false
#| message: false

library(gt)
library(dplyr)

memory_types <- data.frame(
  memory_type = c("의미적 (Semantic)", "에피소드 (Episodic)", "절차적 (Procedural)"),
  what_stored = c("사실 (Facts)", "경험 (Experiences)", "지침 (Instructions)"),
  human_example = c("학교에서 배운 것들", "내가 했던 일들", "본능 또는 운동 기술"),
  agent_example = c("사용자에 대한 사실", "과거 에이전트 행동", "에이전트 시스템 프롬프트")
)

memory_types |>
  gt() |>
  tab_header(
    title = "메모리 유형별 특성"
  ) |>
  cols_label(
    memory_type = "메모리 유형",
    what_stored = "저장 내용",
    human_example = "인간 예시",
    agent_example = "에이전트 예시"
  ) |>
  tab_style(
    style = list(
      cell_fill(color = "#E8F4FD"),
      cell_text(weight = "bold")
    ),
    locations = cells_body(
      columns = memory_type
    )
  ) |>
  tab_options(
    table.width = pct(100),    # 페이지 너비에 맞춤
    table.font.size = px(9),   # 글꼴 크기 소폭 축소
    heading.title.font.size = px(16),
    heading.title.font.weight = "bold"
  )
```

@tbl-memory-types 에서 볼 수 있듯이, 인간의 메모리 체계를 모방한 이러한 분류는 AI 에이전트가 다양한 유형의 정보를 효과적으로 관리할 수 있게 한다. **의미적 메모리**는 사실과 개념적 지식을 저장하여 에이전트의 기본 지식 베이스를 형성한다. **에피소드 메모리**는 과거의 상호작용과 경험을 기록하여 맥락적 이해와 개인화된 대응을 가능하게 한다. **절차적 메모리**는 작업 수행 방법과 프로토콜을 저장하여 일관성 있고 효율적인 행동 패턴을 유지한다.

메모리 저장 능력이 갖춰지면, 에이전트는 현재 작업에 가장 적합한 메모리를 선택하고 활용하는 능력도 함께 개발해야 한다. 예를 들어, 새로운 문제를 해결할 때는 유사한 과거 경험(에피소드 메모리)을 참조하고, 표준 절차가 필요한 경우에는 저장된 프로토콜(절차적 메모리)을 활용하며, 사실 확인이 필요할 때는 지식 베이스(의미적 메모리)를 검색한다.

메모리 계층\index{메모리 계층} 구조는 다음과 같이 구현된다.

```python
class MemoryHierarchy:
    def __init__(self):
        self.sensory_memory = []      # 즉각적 입력
        self.short_term_memory = {}   # 현재 세션
        self.long_term_memory = VectorDB()  # 영구 저장
        
    def write_context(self, information, context_type):
        if context_type == "scratchpad":
            # 작업 중간 결과 저장
            self.short_term_memory[hash(information)] = information
        elif context_type == "long_term":
            # 중요 정보 영구 저장
            self.long_term_memory.add(information)
        elif context_type == "task_log":
            # 작업 기록 저장
            self.append_to_log(information)
```

이러한 계층적 메모리 구조는 다양한 실무 시나리오에서 활용된다. **스크래치패드**는 복잡한 문제를 단계별로 해결할 때 중간 계산 결과나 임시 가설을 저장하는 작업 공간으로 기능한다. 이는 인간이 문제를 풀 때 종이에 메모하는 것과 유사한 역할을 한다. **장기 기억**은 사용자의 선호도, 과거 대화 내용, 학습된 패턴 등을 영구적으로 저장하여, 시간이 지나도 일관성 있고 개인화된 서비스를 제공할 수 있게 한다. **작업 로그**는 수행한 모든 작업과 그 결과를 체계적으로 기록하여, 디버깅, 감사, 성능 분석 등에 활용된다.

### 컨텍스트 격리\index{격리}  {#sec-isolate-context}

컨텍스트 격리(Isolate Context)는 정보의 순수성과 전문성을 유지하기 위한 고급 전략으로, 서로 다른 도메인이나 작업의 정보가 섞여 혼란을 일으키는 것을 방지한다. 이는 마치 병원에서 각 진료과가 독립적으로 운영되면서도 필요시 협진을 통해 협력하는 것과 유사하다. 각 도메인은 고유한 용어, 규칙, 지식 체계를 가지고 있으며, 이들을 무분별하게 혼합하면 오히려 성능 저하와 오류를 초래할 수 있다.

다중 에이전트 오케스트레이션은 이러한 격리 전략의 핵심 구현 방법이다. 각 에이전트는 특정 도메인이나 작업에 특화되어 있으며, 자신만의 독립적인 컨텍스트 공간을 유지한다. 예를 들어, 의료 AI 시스템에서는 진단 에이전트, 처방 에이전트, 의료 기록 관리 에이전트가 각각 독립적으로 작동하면서도, 중앙 조정자를 통해 필요한 정보만을 선택적으로 공유한다. 이러한 아키텍처는 각 에이전트가 자신의 전문 분야에서 최고의 성능을 발휘할 수 있게 하면서도, 전체 시스템의 일관성과 통합성을 유지한다.

```python
class ContextIsolator:
    def __init__(self):
        self.domain_contexts = {}
        self.agent_pool = {}
        
    def isolate_by_domain(self, task, domain):
        # 도메인별 컨텍스트 격리
        if domain not in self.domain_contexts:
            self.domain_contexts[domain] = {
                'knowledge': [],
                'rules': [],
                'state': {}
            }
        
        # 전문 에이전트 할당
        specialized_agent = self.get_or_create_agent(domain)
        return specialized_agent.process(task, self.domain_contexts[domain])
```

격리된 컨텍스트는 단순히 정보를 분리하는 것 이상의 이점을 제공한다. 첫째, **도메인 특화 최적화**가 가능해져 각 분야에 맞는 특수한 처리 방법과 알고리즘을 적용할 수 있다. 둘째, **오류 격리**를 통해 한 도메인에서 발생한 문제가 전체 시스템으로 확산되는 것을 방지한다. 셋째, **확장성**이 향상되어 새로운 도메인이나 기능을 기존 시스템에 영향을 주지 않고 추가할 수 있다. 넷째, **보안과 프라이버시**가 강화되어 민감한 정보를 해당 도메인 내에서만 처리할 수 있다.

::: {.callout-tip}
## 다중 에이전트 아키텍처의 장점
복잡한 작업을 여러 전문 에이전트로 분할하면, 각 에이전트는 자신의 전문 분야에 집중할 수 있고, 전체 시스템은 더 높은 수준의 문제 해결 능력을 갖추게 된다. 이는 "분할 정복(Divide and Conquer)" 전략의 현대적 구현이다.
:::

## 실제 시스템 구현 {#sec-practical-implementations}

### 통합 RAG 시스템 {#sec-integrated-rag}

통합 RAG(Retrieval-Augmented Generation) 시스템은 컨텍스트 공학의 네 가지 핵심 전략을 하나의 일관된 아키텍처로 결합한 실제 구현 사례다. 이 시스템은 사용자 쿼리가 입력되면 먼저 **컨텍스트 격리** 단계에서 쿼리의 도메인과 특성을 분석하여 적절한 처리 경로를 결정한다. 예를 들어, 의료 관련 질문은 의료 전문 컨텍스트로, 법률 질문은 법률 컨텍스트로 라우팅되어 각 분야의 전문성을 유지한다. 

이어지는 **컨텍스트 선택** 단계에서는 벡터 데이터베이스\index{벡터 데이터베이스}, 지식 그래프, 구조화된 데이터베이스 등 다양한 소스에서 관련 정보를 검색한다. 단순한 키워드 매칭을 넘어 의미적 유사도, 시간적 관련성, 정보의 신뢰도 등을 종합적으로 고려하여 가장 적합한 정보를 선별한다. **컨텍스트 압축** 단계는 선택된 정보를 LLM의 제한된 컨텍스트 창에 맞춰 최적화하는 과정으로, 중복 제거, 요약, 구조화 등의 기법을 통해 정보 밀도를 극대화한다.

응답 생성 후에는 **컨텍스트 쓰기** 단계에서 대화 내용, 새로 발견된 정보, 사용자 피드백 등을 체계적으로 저장한다. 이렇게 저장된 정보는 메모리 업데이트를 거쳐 다시 선택 단계로 피드백되어, 시스템이 지속적으로 학습하고 개선되는 순환 구조를 형성한다. 이러한 통합 아키텍처는 각 전략이 독립적으로 작동하면서도 유기적으로 연결되어, 전체 시스템의 성능을 극대화한다.

```{mermaid}
%%| fig-width: 6
%%| fig-cap: "통합 컨텍스트 공학 아키텍처"
%%| label: fig-integrated-architecture
graph LR
    A["사용자<br>쿼리"] --> B[컨텍스트<br>격리]
    B --> C[컨텍스트<br>선택]
    C --> D[컨텍스트<br>압축]
    D --> E[응답<br>생성]
    E --> F[컨텍스트<br>쓰기]
    F --> G[메모리<br>업데이트]
    
    G -.-> C
    
    style B fill:#f9f,stroke:#333,stroke-width:2px
    style C fill:#9ff,stroke:#333,stroke-width:2px
    style D fill:#ff9,stroke:#333,stroke-width:2px
    style F fill:#9f9,stroke:#333,stroke-width:2px
```

### Self-Refine 프레임워크

Self-Refine 프레임워크는 컨텍스트를 자체적으로 평가하고 개선하는 적응형 시스템으로, 인간의 반복적 수정 과정을 모방한 혁신적인 접근법이다. 이 프레임워크의 핵심은 생성된 컨텍스트를 단순히 사용하는 것이 아니라, 지속적으로 평가하고 개선하는 순환 과정에 있다. 시스템은 먼저 현재 컨텍스트의 품질을 다양한 메트릭(관련성, 완전성, 일관성, 효율성 등)을 통해 평가한다. 이 평가 결과를 바탕으로 선택 전략을 조정하여 더 관련성 높은 정보를 찾거나, 압축 알고리즘을 최적화하여 정보 손실을 줄이는 등의 개선 작업을 수행한다.

각 반복 주기마다 시스템은 개선 사항과 품질 점수를 기록하여, 어떤 전략이 효과적이었는지 학습한다. 이러한 메타 학습 능력은 시스템이 다양한 작업과 도메인에 적응할 수 있게 하며, 시간이 지날수록 더 효율적이고 정확한 컨텍스트 관리가 가능해진다. 특히 주목할 점은 이 프레임워크가 외부 피드백 없이도 자체적으로 개선점을 발견하고 적용할 수 있다는 것이다. 예를 들어, 특정 유형의 쿼리에서 반복적으로 낮은 품질 점수가 나온다면, 시스템은 해당 유형에 대한 새로운 처리 전략을 개발하거나 기존 전략의 매개변수를 조정한다.

Self-Refine의 실제 구현에서는 품질 평가를 위한 다양한 휴리스틱과 학습된 모델을 조합하여 사용한다. 또한 계산 효율성을 위해 모든 컨텍스트를 개선하는 것이 아니라, 품질 점수가 특정 임계값 이하인 경우에만 개선 프로세스를 활성화하는 적응적 접근법을 채택한다. 이러한 접근법은 고품질 컨텍스트는 빠르게 처리하면서도, 개선이 필요한 경우에는 충분한 계산 자원을 할당하여 최적의 결과를 도출할 수 있게 한다.

```python
class SelfRefine:
    def improve_context(self, initial_context):
        for iteration in range(self.max_iterations):
            # 1. 컨텍스트 평가
            quality_score = self.evaluate_context(initial_context)
            
            # 2. 선택 전략 개선
            better_selection = self.refine_selection(initial_context)
            
            # 3. 압축 최적화
            optimized_compression = self.optimize_compression(better_selection)
            
            # 4. 결과 저장
            self.write_improvement_log(iteration, quality_score)
            
            if self.is_satisfactory(optimized_compression):
                break
                
            initial_context = optimized_compression
            
        return initial_context
```

## 도전 과제와 미래 방향 {#sec-challenges-and-future}

컨텍스트 공학은 여러 중요한 도전 과제에 직면해 있다. 첫째, **컨텍스트 오염(Context Poisoning)**은 관련 없거나 잘못된 정보가 컨텍스트에 포함되어 에이전트의 판단력을 흐리는 현상으로, 이는 AI 시스템의 신뢰성을 크게 저하시킬 수 있다. 이를 해결하기 위해서는 엄격한 정보 선택 기준과 체계적인 검증 프로세스가 필수적이다. 둘째, **컨텍스트 혼란(Context Confusion)**은 너무 많은 정보나 서로 모순되는 정보로 인해 에이전트가 명확한 결정을 내리지 못하는 상황을 말한다. 효과적인 정보 압축과 우선순위화 전략이 이 문제의 핵심 해결책이 된다. 셋째, **컨텍스트 충돌(Context Conflicts)**은 서로 다른 도메인이나 출처의 정보가 상충할 때 발생하며, 이는 격리 전략을 통해 각 도메인의 정보를 독립적으로 관리함으로써 해결할 수 있다.

::: {.callout-important}
## 균형의 중요성
네 가지 전략은 서로 보완적이며, 효과적인 컨텍스트 공학은 이들 간의 적절한 균형을 찾는 것이다.
:::

컨텍스트 공학의 미래는 더욱 지능적이고 자율적인 시스템으로의 진화를 예고한다. 가장 주목할 만한 발전은 **자동화된 전략 선택**으로, AI가 주어진 상황과 작업 특성을 분석하여 최적의 전략 조합을 스스로 결정하는 능력을 갖추게 될 것이다. 이는 인간의 개입 없이도 다양한 상황에 유연하게 대응할 수 있는 진정한 자율 시스템의 실현을 의미한다. 또한 **동적 컨텍스트 조정**은 작업이 진행됨에 따라 실시간으로 네 가지 전략의 비중을 조절하여, 각 단계에서 최적의 성능을 유지할 수 있게 한다. **크로스 에이전트 컨텍스트 공유**는 격리된 컨텍스트 간에도 필요한 정보를 선택적으로 공유할 수 있는 메커니즘을 제공하여, 전문성을 유지하면서도 협업의 효율성을 극대화할 것이다. 마지막으로 **컨텍스트 품질 메트릭**의 개발은 각 전략의 효과성을 객관적으로 측정하고 평가할 수 있는 표준화된 체계를 제공하여, 지속적인 개선과 최적화를 가능하게 할 것이다.

실제 시스템에 컨텍스트 공학을 적용할 때는 여러 실무적 측면을 신중히 고려해야 한다. **선택과 압축의 균형**은 정보 손실을 최소화하면서도 처리 효율성을 극대화하는 최적점을 찾는 것이 관건이다. 너무 많은 정보를 선택하면 압축의 부담이 커지고, 과도한 압축은 중요한 정보의 손실로 이어질 수 있다. **쓰기와 격리의 조화**는 정보의 접근성과 도메인별 전문성 사이에서 적절한 균형점을 찾아야 한다. 모든 정보를 중앙화하면 접근은 쉬워지지만 전문성이 희석될 수 있고, 과도한 격리는 정보 사일로를 만들어 협업을 방해할 수 있다.

::: {.callout-note}
## 핵심 원칙

컨텍스트 공학의 본질은 "적시에 적절한 정보를 적절한 형태로" 제공하는 것이다. 선택(Select), 압축(Compress), 쓰기(Write), 격리(Isolate)의 네 가지 전략을 조화롭게 활용하여[@mei2025surveycontextengineeringlarge], 제한된 컨텍스트 창을 가진 LLM도 복잡하고 장기적인 작업을 효과적으로 수행할 수 있게 한다[@langchain2024context].
:::

이러한 컨텍스트 공학의 이론적 기반 위에서, 다음 장에서는 OpenAI API를 활용한 실제 구현 사례와 프로덕션 환경에서의 적용 방법을 구체적으로 살펴보겠다. 특히 API 호출 최적화, 비용 효율적인 컨텍스트 관리, 대규모 시스템에서의 확장성 확보 방안에 중점을 둘 것이다.
